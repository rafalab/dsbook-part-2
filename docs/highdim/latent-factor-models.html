<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Rafael A. Irizarry">
<title>25&nbsp; Latent Factor Models – Introduction to Data Science</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../highdim/reading-highdim.html" rel="next">
<link href="../highdim/regularization.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-8f18353b6674da201bf96e4b700cba6a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../highdim/intro-highdim.html">High Dimensional Data</a></li><li class="breadcrumb-item"><a href="../highdim/latent-factor-models.html"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Latent Factor Models</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Introduction to Data Science</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/rafalab/dsbook-part-2" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Front Matter</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../summaries/intro-summaries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Summary Statistics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../summaries/distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../summaries/numerical-summaries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Numerical Summaries</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../summaries/comparing-groups.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Comparing Groups</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../summaries/reading-summaries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recommended Reading</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../prob/intro-to-prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob/connecting-data-and-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Connecting Data and Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob/discrete-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Discrete Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob/continuous-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Continuous Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob/random-variables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Random Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob/sampling-models-and-clt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sampling Models and the Central Limit Theorem</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob/reading-prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recommended Reading</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../inference/intro-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistical Inference</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/estimates-confidence-intervals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Estimates and Confidence Intervals</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Data-Driven Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Bayesian Statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/hierarchical-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Hierarchical Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/hypothesis-testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/bootstrap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Bootstrap</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/reading-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recommended Reading</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../linear-models/intro-to-linear-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear Models</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Introduction to Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/linear-model-framework.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">The Linear Model Framework</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/treatment-effect-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Treatment Effect Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Generalized Linear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/association-not-causation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Association Is Not Causation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/multivariable-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Multivariable Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/reading-lm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recommended Reading</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../highdim/intro-highdim.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">High Dimensional Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/matrices-in-R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Working with Matrices in R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/linear-algebra.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Applied Linear Algebra</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/dimension-reduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Dimension Reduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/regularization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Regularization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/latent-factor-models.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Latent Factor Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/reading-highdim.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recommended reading</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../ml/intro-ml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/notation-and-terminology.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Notation and Terminology</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/evaluation-metrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Performance Metrics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/conditionals-and-smoothing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Conditional Expectations and Smoothing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/resampling-methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Resampling and Model Assessment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/algorithms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Supervised Learning Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/ml-in-practice.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Building Machine Learning Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Unsupervised Learning: Clustering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/reading-ml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recommended reading</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#sec-factor-analysis" id="toc-sec-factor-analysis" class="nav-link active" data-scroll-target="#sec-factor-analysis"><span class="header-section-number">25.1</span> Factor analysis</a></li>
  <li><a href="#connection-to-pca" id="toc-connection-to-pca" class="nav-link" data-scroll-target="#connection-to-pca"><span class="header-section-number">25.2</span> Connection to PCA</a></li>
  <li>
<a href="#case-study-recommendation-systems" id="toc-case-study-recommendation-systems" class="nav-link" data-scroll-target="#case-study-recommendation-systems"><span class="header-section-number">25.3</span> Case study: recommendation systems</a>
  <ul class="collapse">
<li><a href="#a-latent-factor-model-for-movie-ratings" id="toc-a-latent-factor-model-for-movie-ratings" class="nav-link" data-scroll-target="#a-latent-factor-model-for-movie-ratings">A latent factor model for movie ratings</a></li>
  <li><a href="#regularization" id="toc-regularization" class="nav-link" data-scroll-target="#regularization">Regularization</a></li>
  <li><a href="#visualizing-factors" id="toc-visualizing-factors" class="nav-link" data-scroll-target="#visualizing-factors">Visualizing factors</a></li>
  <li><a href="#practical-considerations" id="toc-practical-considerations" class="nav-link" data-scroll-target="#practical-considerations">Practical considerations</a></li>
  </ul>
</li>
  <li><a href="#singular-value-decomposition" id="toc-singular-value-decomposition" class="nav-link" data-scroll-target="#singular-value-decomposition"><span class="header-section-number">25.4</span> Singular Value Decomposition</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">25.5</span> Exercises</a></li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/rafalab/dsbook-part-2/blob/main/highdim/latent-factor-models.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/rafalab/dsbook-part-2/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../highdim/intro-highdim.html">High Dimensional Data</a></li><li class="breadcrumb-item"><a href="../highdim/latent-factor-models.html"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Latent Factor Models</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title"><span id="sec-latent-factor-models" class="quarto-section-identifier"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Latent Factor Models</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><p>Many data problems involve large matrices with structure we cannot see directly. Latent factor models provide a powerful way to uncover this hidden structure. The key idea is that observed data often reflect the influence of a smaller number of unobserved (latent) features. These latent factors capture patterns such as groups of similar individuals, groups of similar items, or shared underlying attributes that drive the observed values.</p>
<p>In the previous chapter, we introduced the model</p>
<p><span class="math display">\[
Y_{ij} = \mu + \alpha_i + \beta_j + \varepsilon_{ij}
\]</span></p>
<p>to describe movie ratings. This model accounts for differences between users through <span class="math inline">\(\alpha_i\)</span> and differences between movies through <span class="math inline">\(\beta_j\)</span>. However, it treats all movies and all users as unrelated beyond these simple averages. In practice, we know that groups of movies tend to be liked by the same kinds of users, and groups of users tend to give similar ratings to the same kinds of movies. This shared structure is not captured by user and movie effects alone.</p>
<p>To see this, we compute residuals</p>
<p><span class="math display">\[
r_{ij} = y_{ij} - (\hat{\mu} + \hat{\alpha}_i + \hat{\beta}_j)
\]</span></p>
<p>by fitting the model to the <code>train_set</code> dataset using the <code>fit_als</code> function, both defined in the previous chapter,</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu">fit_als</span><span class="op">(</span>lambda <span class="op">=</span> <span class="fl">3.636364e-05</span><span class="op">)</span></span>
<span><span class="va">train_set</span><span class="op">[</span>, <span class="va">resid</span> <span class="op">:=</span> <span class="va">rating</span> <span class="op">-</span> <span class="fu">clamp</span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">mu</span> <span class="op">+</span> <span class="va">fit</span><span class="op">$</span><span class="va">a</span><span class="op">[</span><span class="va">userId</span><span class="op">]</span> <span class="op">+</span> <span class="va">fit</span><span class="op">$</span><span class="va">b</span><span class="op">[</span><span class="va">movieId</span><span class="op">]</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>and comparing the residuals for <em>The Godfather</em> with three other films:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="latent-factor-models_files/figure-html/movie-cor-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>These correlations range from strongly positive to negative. Specifically the correlations between <em>The Godfather</em> and <em>The Godfather part II</em>, <em>Goodfellas</em>, and <em>Sleepless in Seattle</em> are 0.84, 0.49, and -0.42, respectively. Users who love <em>The Godfather</em> also tend to like <em>The Godfather Part II</em> and <em>Goodfellas</em>, but often dislike <em>Sleepless in Seattle</em>. These kinds of relationships are because movies share latent characteristics: genre, tone, style, era, or audience appeal. Similarly, users have latent traits that make them prefer some types of movies over others.</p>
<p>Latent factor models are designed to capture exactly this type of structure. Instead of estimating thousands of separate parameters, they represent users and movies in a lower-dimensional space defined by a small number of latent features. The winning team of the Netflix Prize competition relied heavily on this idea, using latent factor models to achieve an improvement in predictive accuracy.</p>
<p>Although recommendation systems are one of the most famous applications, latent factor models are widely used in other fields, such as genomics (to model hidden biological structure), text analysis (topics in documents), marketing (customer segmentation), and finance (risk factors underlying asset returns).</p>
<p>In this chapter, we introduce latent factor models in the context of recommendation systems, connect them to principal component analysis (PCA), and show how the singular value decomposition (SVD) provides a unifying mathematical foundation. We will build models that capture hidden structure in rating data and show how these models further improve prediction accuracy.</p>
<section id="sec-factor-analysis" class="level2" data-number="25.1"><h2 data-number="25.1" class="anchored" data-anchor-id="sec-factor-analysis">
<span class="header-section-number">25.1</span> Factor analysis</h2>
<p>We start with a simple simulated example. Specifically, we simulate ratings <span class="math inline">\(Y_{ij}\)</span> for six movies and 120 users. For simplicity we assume that these ratings have been adjusted for the movie and user effects, as described in <a href="regularization.html" class="quarto-xref"><span>Chapter 24</span></a>. We stored the results for 120 user and 6 movie effects in the object <code>y</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 120   6</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>If we examine the correlation between movies based on user ratings, we notice a pattern:</p>
<div class="small-code">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span><span class="co">#&gt;                      Godfather Godfather 2 Goodfellas Scent of a Woman You've Got Mail Sleepless in Seattle</span></span>
<span><span class="co">#&gt; Godfather                1.000       0.671      0.558           -0.527          -0.734               -0.721</span></span>
<span><span class="co">#&gt; Godfather 2              0.671       1.000      0.471           -0.450          -0.649               -0.739</span></span>
<span><span class="co">#&gt; Goodfellas               0.558       0.471      1.000           -0.888          -0.487               -0.505</span></span>
<span><span class="co">#&gt; Scent of a Woman        -0.527      -0.450     -0.888            1.000           0.451                0.475</span></span>
<span><span class="co">#&gt; You've Got Mail         -0.734      -0.649     -0.487            0.451           1.000                0.756</span></span>
<span><span class="co">#&gt; Sleepless in Seattle    -0.721      -0.739     -0.505            0.475           0.756                1.000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>It appears that ratings are positively correlated within genres, for example, among mob movies or among romance movies, and negatively correlated across the two genres. In statistics, such patterns are often explained by factors: unobserved, or latent, variables that account for the correlations or associations among the observed variables. Under certain assumptions, which we will describe below, these latent factors can be estimated from the data and used to capture the underlying structure driving the correlations.</p>
<p>One approach is to use our knowledge of movies genres to define a factor that distinguishes between mob and romance movies:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">q</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We code mob movies with <code>-1</code> and romance movies with <code>1</code>.</p>
<p>To quantify each user’s genre preferences, we fit a separate linear model for every user <span class="math inline">\(i\)</span> (rows of <code>y</code>) by using <code>apply</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">y</span>, <span class="fl">1</span>, <span class="kw">function</span><span class="op">(</span><span class="va">y_i</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y_i</span> <span class="op">~</span> <span class="va">q</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">$</span><span class="va">coef</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We include <code>-1</code> in the formula because the residuals were constructed to have mean 0, so no intercept is needed.</p>
<p>Each call to <code>lm</code> returns an estimated coefficients representing the difference in average ratings between mob and romance movies. A positive value indicates a preference for mob movies, a negative value indicates a preference for romance movies, and values near 0 suggest no strong preference.</p>
<p>Collecting these across users gives us <code>p</code>, a vector with one entry per user. The histogram below shows users cluster into these three type:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">p</span>, breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span>, <span class="fl">2</span>, <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="latent-factor-models_files/figure-html/factor-histogram-example-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>We now show that we can approximate each rating <span class="math inline">\(Y_{ij}\)</span> using just the product of two vectors: one describing user preferences (<span class="math inline">\(p\)</span>) and one describing movie characteristics (<span class="math inline">\(q\)</span>). To work with matrix algebra, we convert the vectors into matrices and multiply them:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span></span>
<span><span class="va">q</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">q</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">p</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">q</span><span class="op">)</span>, <span class="va">y</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="latent-factor-models_files/figure-html/e-vs-pq-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>The points fall roughly along the diagonal, which means the model captures a good amount of structure in the data. However, there is still substantial unexplained variation. Even after removing the “mob vs.&nbsp;romance” effect, we still see correlation patterns:</p>
<div class="small-code">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="va">p</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">q</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;                      Godfather Godfather 2 Goodfellas Scent of a Woman You've Got Mail Sleepless in Seattle</span></span>
<span><span class="co">#&gt; Godfather                1.000       0.185     -0.545            0.557          -0.280               -0.198</span></span>
<span><span class="co">#&gt; Godfather 2              0.185       1.000     -0.618            0.594          -0.186               -0.364</span></span>
<span><span class="co">#&gt; Goodfellas              -0.545      -0.618      1.000           -0.671           0.619                0.650</span></span>
<span><span class="co">#&gt; Scent of a Woman         0.557       0.594     -0.671            1.000          -0.641               -0.656</span></span>
<span><span class="co">#&gt; You've Got Mail         -0.280      -0.186      0.619           -0.641           1.000                0.353</span></span>
<span><span class="co">#&gt; Sleepless in Seattle    -0.198      -0.364      0.650           -0.656           0.353                1.000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>Looking more closely, this structure appears to come from whether or not Al Pacino is in the movie. This suggests we can improve the model by adding a second latent factor, one that distinguishes Pacino films from non-Pacino films. We do this by adding a second column to <code>q</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">q</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span><span class="op">)</span>,</span>
<span>           <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now each movie is described by <em>two latent factors</em>:</p>
<ol type="1">
<li>Mob vs.&nbsp;romance</li>
<li>Al Pacino vs.&nbsp;not Al Pacino</li>
</ol>
<p>We then fit a model for each user to estimate their preference for each factor:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">y</span>, <span class="fl">1</span>, <span class="kw">function</span><span class="op">(</span><span class="va">y_i</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y_i</span> <span class="op">~</span> <span class="va">q</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">$</span><span class="va">coef</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Because <code>q</code> now has two columns, <code>lm</code> returns two coefficients per user. The first captures mob/romance preference, and the second captures whether the user tends to like Al Pacino films.</p>
<p>We use <code>t</code> (transpose) because <code>apply</code> stacks results as columns, but we want one user per row.</p>
<p>With two factors, our predictions improve:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">p</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">q</span><span class="op">)</span>, <span class="va">y</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="latent-factor-models_files/figure-html/e-vs-pq-2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>And now, if we look at the residual correlation</p>
<div class="small-code">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="va">p</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">q</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;                      Godfather Godfather 2 Goodfellas Scent of a Woman You've Got Mail Sleepless in Seattle</span></span>
<span><span class="co">#&gt; Godfather              1.00000     -0.3597    0.00716          0.00716          0.2412              0.41857</span></span>
<span><span class="co">#&gt; Godfather 2           -0.35970      1.0000   -0.04429         -0.04429          0.4955              0.20741</span></span>
<span><span class="co">#&gt; Goodfellas             0.00716     -0.0443    1.00000          1.00000         -0.0339             -0.00554</span></span>
<span><span class="co">#&gt; Scent of a Woman       0.00716     -0.0443    1.00000          1.00000         -0.0339             -0.00554</span></span>
<span><span class="co">#&gt; You've Got Mail        0.24118      0.4955   -0.03395         -0.03395          1.0000             -0.27145</span></span>
<span><span class="co">#&gt; Sleepless in Seattle   0.41857      0.2074   -0.00554         -0.00554         -0.2714              1.00000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>there is no clear pattern left. The two latent factors now explain the main structure in the data.</p>
<p>This approximation with two factors can be written as:</p>
<p><span class="math display">\[
Y_{ij} \approx p_{i1}q_{j1} + p_{i2}q_{j2}, i = 1 \dots, I \mbox{ and } j = 1, \dots, J
\]</span> with <span class="math inline">\(I\)</span> the number of users and <span class="math inline">\(J\)</span> the number of movies.</p>
<p>Using matrix representation we can rewrite the above question like this:</p>
<p><span class="math display">\[
\mathbf{Y} \approx \mathbf{P}\mathbf{Q}^\top
\]</span> with <span class="math inline">\(\mathbf{Y}\)</span> an <span class="math inline">\(I\times J\)</span> matrix with entries <span class="math inline">\(Y_{ij}\)</span>, <span class="math inline">\(\mathbf{P}\)</span> a <span class="math inline">\(I\times K\)</span> matrix with entries <span class="math inline">\(p_{ik}\)</span>, and <span class="math inline">\(\mathbf{Q}\)</span> a <span class="math inline">\(J\times K\)</span> matrix with entries <span class="math inline">\(q_{jk}\)</span>.</p>
<p>This analysis provides insights into the process generating our data since <span class="math inline">\(\mathbf{P}\)</span> contains user-specific parameters and <span class="math inline">\(\mathbf{Q}\)</span> contains movie-specific parameters. The approach is often referred to as <em>matrix factorization</em> because the rating matrix has been <em>factorized</em> into two lower-dimensional, interpretable matrices.</p>
<p>Note that the apporach also provides compression since the <span class="math inline">\(120 \times 6 = 720\)</span> observations can be well approximated by a matrix multiplication of a <span class="math inline">\(120 \times 2\)</span> matrix <span class="math inline">\(\mathbf{P}\)</span> and a <span class="math inline">\(6 \times 2\)</span> matrix <span class="math inline">\(\mathbf{Q}\)</span>, a total of <span class="math inline">\(252\)</span> parameters.</p>
<p>In our example with simulated data, we deduced the factors <span class="math inline">\(\mathbf{q}_1\)</span> and <span class="math inline">\(\mathbf{q}_2\)</span> from the sample correlation and our knowledge of movies. These ended up working well. However, in general deducing factors is not this easy. Furthermore, factors that provide good approximation might be more complicated than containing just two values. For example, <em>The Godfather III</em> has a romantic subplot so we might not know what value to assign it in <code>q_1</code>.</p>
<p>So, can we estimate the factors? A challenge is that if <span class="math inline">\(\mathbf{P}\)</span> is unknown, our model is no longer linear: we can’t use <code>lm</code> to estimate both <span class="math inline">\(\mathbf{P}\)</span> and <span class="math inline">\(\mathbf{Q}\)</span>. In the next sections, we describe how PCA can be used to estimate <span class="math inline">\(\mathbf{P}\)</span> and <span class="math inline">\(\mathbf{Q}\)</span>.</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>We used <code>apply</code> and <code>lm</code> to estimate <code>p</code>. But there is a faster way to compute these estimates using linear algebra.</p>
<p>The <code>lm</code> function works by minimizing the sum of squared residuals. In matrix form, this leads to the normal equations:</p>
<p><span class="math display">\[
(\mathbf{q}^\top\mathbf{q}) \, \hat{\mathbf{p}}_i = \mathbf{q}^\top \mathbf{y}_i
\]</span></p>
<p>where <span class="math inline">\(\mathbf{y}_i\)</span> is the column vector representing the <span class="math inline">\(i\)</span>-th row of <code>y</code> passed to the <code>apply</code> call.</p>
<p>The key observation is that <span class="math inline">\(\mathbf{q}\)</span> is the same for every user, so running <code>lm</code> repeatedly is wasteful: it recomputes the same matrix operations each time. Instead, we can solve the system once and apply it efficiently to all users by using matrix operations:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/qr.html">qr.solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/crossprod.html">crossprod</a></span><span class="op">(</span><span class="va">q</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">q</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This computes all <span class="math inline">\(\hat{\mathbf{p}}_i\)</span> values at once, avoiding thousands of separate model fits.</p>
</div>
</div>
</div>
</section><section id="connection-to-pca" class="level2" data-number="25.2"><h2 data-number="25.2" class="anchored" data-anchor-id="connection-to-pca">
<span class="header-section-number">25.2</span> Connection to PCA</h2>
<p>Notice that in <a href="dimension-reduction.html#sec-pca" class="quarto-xref"><span>Section 23.5</span></a> we learned that if we perform PCA on a matrix <span class="math inline">\(\mathbf{Y}\)</span>, we obtain a transformation <span class="math inline">\(\mathbf{V}\)</span> that permits us to rewrite:</p>
<p><span class="math display">\[
\mathbf{Y} = \mathbf{Z} \mathbf{V}^\top
\]</span></p>
<p>with <span class="math inline">\(\mathbf{Z}\)</span> the matrix of principal components.</p>
<p>Let’s perform PCA on the <span class="math inline">\(\mathbf{Y}\)</span> constructed in the previous section and examine the results:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pca</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/prcomp.html">prcomp</a></span><span class="op">(</span><span class="va">y</span>, center <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>First, notice that the first two PCs explain over 85% of the variability:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pca</span><span class="op">$</span><span class="va">sdev</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">pca</span><span class="op">$</span><span class="va">sdev</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.6939 0.1790 0.0402 0.0313 0.0303 0.0253</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, notice that the first column of <span class="math inline">\(\mathbf{V}\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pca</span><span class="op">$</span><span class="va">rotation</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span></span>
<span><span class="co">#&gt;            Godfather          Godfather 2           Goodfellas </span></span>
<span><span class="co">#&gt;                0.306                0.261                0.581 </span></span>
<span><span class="co">#&gt;     Scent of a Woman      You've Got Mail Sleepless in Seattle </span></span>
<span><span class="co">#&gt;               -0.570               -0.294               -0.300</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>is assigning positive values to the mob movies and negative values to the romance movies.</p>
<p>The second column:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pca</span><span class="op">$</span><span class="va">rotation</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span></span>
<span><span class="co">#&gt;            Godfather          Godfather 2           Goodfellas </span></span>
<span><span class="co">#&gt;                0.354                0.377               -0.382 </span></span>
<span><span class="co">#&gt;     Scent of a Woman      You've Got Mail Sleepless in Seattle </span></span>
<span><span class="co">#&gt;                0.437               -0.448               -0.442</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>is coding for Al Pacino movies.</p>
<p>PCA is automatically discovering the structure we inferred using our knowledge of the movies. This is not a coincidence, there is a mathematical connection that explains why PCA aligns with these latent patterns.</p>
<p>To see this assume that the data <span class="math inline">\(\mathbf{Y}\)</span> follows the model:</p>
<p><span class="math display">\[
Y_{ij} = \sum_{k=1}^K p_{ik}q_{jk} + \varepsilon_{ij}, i=1,\dots,I, \, j = 1,\dots J \mbox{ or }
\mathbf{Y} =  \mathbf{P}\mathbf{Q} ^\top + \boldsymbol{\varepsilon}
\]</span> with the constraint</p>
<p><span class="math display">\[
\mathbf{Q}^\top\mathbf{Q} = \mathbf{I}
\]</span></p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>To understand why we need this constraint, notice that without it the model is not uniquely defined, it is <em>unidentifiable</em>. For example, we can multiply any column of <span class="math inline">\(\mathbf{P}\)</span> by a constant <span class="math inline">\(c &gt; 0\)</span> and divide the corresponding column of <span class="math inline">\(\mathbf{Q}\)</span> by the same constant, and the product <span class="math inline">\(\mathbf{P}\mathbf{Q}^\top\)</span> remains unchanged. This constraint removes the scaling ambiguity and ensures that the factorization has a well-defined form.</p>
</div>
</div>
</div>
<p>The first <span class="math inline">\(K\)</span> columns of the principal components and the associated rotation matrix provide estimates of <span class="math inline">\(\mathbf{P}\)</span> and <span class="math inline">\(\mathbf{Q}\)</span>, respectively. In other words, PCA can be viewed as a special case of latent factor modeling where the latent factors are chosen to be orthogonal and ordered by the variance they explain. This explains why PCA naturally recovers interpretable patterns, such as genre preferences or actor-specific effects, without us explicitly coding them into the model.</p>
<p>Another way to see this connection is through optimization. PCA can be formulated as the solution to a least squares problem: among all possible <span class="math inline">\(K\)</span>-dimensional projections of the data, PCA finds the one that minimizes the reconstruction error, that is, the sum of squared differences between the original data <span class="math inline">\(\mathbf{Y}\)</span> and its approximation <span class="math inline">\(\mathbf{P}\mathbf{Q}^\top\)</span>. In this sense, PCA provides the best rank-<span class="math inline">\(K\)</span> approximation of <span class="math inline">\(\mathbf{Y}\)</span> in the least squares sense.</p>
<p>This dual interpretation, both as a factor model and as a least squares optimizer, highlights why PCA is such a powerful tool for uncovering hidden structure in high-dimensional data: it compresses the data efficiently while also providing factors that capture the dominant sources of variation.</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Even with the orthogonality constraint, the PCA solution is not completely unique.<br>
There remains a <em>sign indeterminacy</em>: we can flip the sign of any column in <span class="math inline">\(\mathbf{P}\)</span> and the corresponding column in <span class="math inline">\(\mathbf{Q}\)</span> (multiply one by <span class="math inline">\(-1\)</span> and the other by <span class="math inline">\(-1\)</span>) without changing the product <span class="math inline">\(\mathbf{P}\mathbf{Q}^\top\)</span>.<br>
Thus, the factorization is identifiable only up to these sign changes.</p>
</div>
</div>
</div>
</section><section id="case-study-recommendation-systems" class="level2" data-number="25.3"><h2 data-number="25.3" class="anchored" data-anchor-id="case-study-recommendation-systems">
<span class="header-section-number">25.3</span> Case study: recommendation systems</h2>
<p>We now move back from the small simulated example to the real Movielens dataset. In the previous section, we used a toy setting to illustrate how latent factors can capture patterns such as “mob vs.&nbsp;romance” or “Al Pacino vs.&nbsp;not Al Pacino”. Here, we show that similar latent structure is present in the real movie ratings and that we can exploit it to further improve predictions.</p>
<p>Starting from the residuals of our regularized user + movie model (introduced in <a href="regularization.html" class="quarto-xref"><span>Chapter 24</span></a>), we can examine how movie ratings correlate after accounting for overall averages and user and movie effects. Focusing on a small set of well-known titles, we compute the correlation matrix of these residuals:</p>
<div class="small-code">
<div class="cell" data-layout-align="center">
<pre><code>#&gt;                      Godfather Godfather II Goodfellas Scent of a Woman You've Got Mail Sleepless in Seattle
#&gt; Godfather                 1.00         0.84       0.49             0.46           -0.36                -0.42
#&gt; Godfather II              0.84         1.00       0.47             0.21           -0.25                -0.43
#&gt; Goodfellas                0.49         0.47       1.00             0.04           -0.27                -0.45
#&gt; Scent of a Woman          0.46         0.21       0.04             1.00           -0.37                -0.50
#&gt; You've Got Mail          -0.36        -0.25      -0.27            -0.37            1.00                 0.43
#&gt; Sleepless in Seattle     -0.42        -0.43      -0.45            -0.50            0.43                 1.00</code></pre>
</div>
</div>
<p>As in the simulated example, we see clear correlation patterns. For instance, <em>The Godfather</em>, <em>The Godfather Part II</em>, and <em>Goodfellas</em> share similar residuals, while romantic comedies show different behavior. This suggests that ratings are influenced by <em>latent characteristics</em> that group movies and users in meaningful ways.</p>
<section id="a-latent-factor-model-for-movie-ratings" class="level3"><h3 class="anchored" data-anchor-id="a-latent-factor-model-for-movie-ratings">A latent factor model for movie ratings</h3>
<p>This motivates extending our earlier model. We now incorporate latent factors that capture similarities between movies and users. This leads us to a simplified version of the approach used by the winning Netflix Prize team, which combined latent factor models with the regularization methods developed in <a href="regularization.html" class="quarto-xref"><span>Chapter 24</span></a>.</p>
<p>To account for interactions such as these, we use a latent factor model. Specifically, we extend the model from <a href="regularization.html" class="quarto-xref"><span>Chapter 24</span></a> to include factors that capture similarities between movies:</p>
<p><span class="math display">\[
Y_{ij} = \mu + \alpha_i + \beta_j + \sum_{k=1}^K p_{ik}q_{jk} + \varepsilon_{ij}
\]</span></p>
<p>Recall that, as explained in the previous chapter, we do not observe all <span class="math inline">\((i,j)\)</span> combinations. Writing the data as an <span class="math inline">\(I \times J\)</span> matrix <span class="math inline">\(\mathbf{Y}\)</span>, with <span class="math inline">\(I\)</span> users and <span class="math inline">\(J\)</span> movies, would produce many missing values.</p>
<p>However, the sum <span class="math inline">\(\sum_{k=1}^K p_{ik}q_{jk}\)</span> can be expressed as the <span class="math inline">\(I \times J\)</span> matrix product <span class="math inline">\(\mathbf{P}\mathbf{Q}^\top\)</span>, where <span class="math inline">\(\mathbf{P}\)</span> is an <span class="math inline">\(I \times K\)</span> matrix and <span class="math inline">\(\mathbf{Q}\)</span> is a <span class="math inline">\(J \times K\)</span> matrix. Estimating all parameters effectively fills in every cell of the <span class="math inline">\(I \times J\)</span> matrix, giving predictions for all <span class="math inline">\((i,j)\)</span> pairs.</p>
<p>So if this latent factor model is a good approximation, we don’t actually need to observe every user-movie rating to make predictions. Instead, we just need enough observed ratings to estimate the latent factor matrices <span class="math inline">\(\mathbf{P}\)</span> (for users) and <span class="math inline">\(\mathbf{Q}\)</span> (for movies). Once we have these matrices, we can predict any user-movie combination, even those not seen in the training data, simply by computing:</p>
<p><span class="math display">\[
\hat{y}_{ij} \approx \hat{\mu} + \hat{\alpha}_i + \hat{\beta}_j + \hat{p}_i^\top \hat{q}_j
\]</span></p>
</section><section id="regularization" class="level3"><h3 class="anchored" data-anchor-id="regularization">Regularization</h3>
<p>Given the large number of parameters and the sparsity of the data, especially for movies with few ratings, it is appropriate to use penalized least squares. We therefore minimize:</p>
<p><span class="math display">\[
\frac{1}{N}
\sum_{i,j} \left[Y_{ij} - \left(\mu + \alpha_i + \beta_j + \sum_{k=1}^K p_{ik}q_{jk}\right)\right]^2 +
\lambda_1 \left(
\|\boldsymbol{\alpha}\|^2 +
\|\boldsymbol{\beta}\|^2
\right) +
\lambda_2
\sum_{k=1}^K \left( \|\mathbf{p}_k\|^2+
\|\mathbf{q}_k\|^2
\right)
\]</span></p>
<p>Here, <span class="math inline">\(N\)</span> is the number of observed ratings, <span class="math inline">\(I\)</span> the number of users, and <span class="math inline">\(J\)</span> the number of movies. The vectors <span class="math inline">\(\boldsymbol{\alpha}\)</span> and <span class="math inline">\(\boldsymbol{\beta}\)</span> are the user and movie effects, <span class="math inline">\(\boldsymbol{\alpha} = (\alpha_1,\dots,\alpha_I)^\top\)</span> and <span class="math inline">\(\boldsymbol{\beta} = (\beta_1,\dots,\beta_J)^\top\)</span>. The vectors <span class="math inline">\(\mathbf{p}_k = (p_{1k}, \dots, p_{Ik})^\top\)</span> and <span class="math inline">\(\mathbf{q}_k = (q_{1k}, \dots, q_{Jk})^\top\)</span> are the <span class="math inline">\(k\)</span>-th latent factor components. Recall that <span class="math inline">\(|\boldsymbol{\alpha}|^2\)</span> denotes the sum of squares, <span class="math inline">\(\sum_{i=1}^I \alpha_i^2\)</span>.</p>
<p>We use two penalties: <span class="math inline">\(\lambda_1\)</span> for the linear effects (the <span class="math inline">\(\alpha\)</span>s and <span class="math inline">\(\beta\)</span>s), and <span class="math inline">\(\lambda_2\)</span> for the latent factors. This lets us regularize the two components differently, reflecting their distinct roles in the model.</p>
<p>How do we estimate the parameters in this model? The challenge comes from the fact that both the <span class="math inline">\(p\)</span>s and <span class="math inline">\(q\)</span>s are unknown and appear multiplied together, making the model nonlinear in its parameters. In earlier sections, we highlighted the connection between factor analysis and principal component analysis (PCA), and showed that in settings with complete data, PCA can be used to estimate the latent factors of a factor analysis model.</p>
<p>However, recommendation systems present a critical complication: the rating matrix is extremely sparse. Most users only rate a small subset of movies, so the data matrix has many missing entries. PCA and related approaches require a fully observed matrix, so they cannot be applied directly in this context. In addition, while PCA provides least squares estimates, here we want to use <em>penalized least squares</em>, which allows us to regularize the parameters and avoid overfitting when the data for some users or movies are limited.</p>
<p>To address these challenges, we again turn to the <em>Alternating Least Squares (ALS)</em> algorithm described in <a href="regularization.html#sec-movie-effects" class="quarto-xref"><span>Section 24.1.7</span></a>. The key idea is to alternately estimate each column of <span class="math inline">\(\mathbf{P}\)</span> and <span class="math inline">\(\mathbf{Q}\)</span>: fix all columns except one, and solve for that one column using penalized least squares, then switch across all columns. This alternating approach also extends naturally to penalized versions of the model, where user and movie effects and latent factors are regularized separately. For these reasons, ALS has become one of the standard approaches for fitting latent factor models in recommendation systems, where sparsity makes direct application of PCA infeasible.</p>
<p>The <strong>dslabs</strong> package provides the <code>fit_recommender_model</code> function, which implements a latent factor model with regularization:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">train_set</span>, <span class="fu">fit_recommender_model</span><span class="op">(</span><span class="va">rating</span>, <span class="va">userId</span>, <span class="va">movieId</span>, reltol<span class="op">=</span><span class="fl">1e-6</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can learn more about the function, including default parameter choices, by running <code>?fit_recommender_model</code> and examining the source code.</p>
<p>Once we have a fitted model, we can build predictions for the test set and compute the RMSE:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">i</span> <span class="op">&lt;-</span> <span class="va">test_set</span><span class="op">$</span><span class="va">userId</span></span>
<span><span class="va">j</span> <span class="op">&lt;-</span> <span class="va">test_set</span><span class="op">$</span><span class="va">movieId</span></span>
<span><span class="va">resid</span> <span class="op">&lt;-</span> <span class="va">test_set</span><span class="op">$</span><span class="va">rating</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">mu</span> <span class="op">+</span> <span class="va">a</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">+</span> <span class="va">b</span><span class="op">[</span><span class="va">j</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">p</span><span class="op">[</span><span class="va">i</span>,<span class="op">]</span><span class="op">*</span><span class="va">q</span><span class="op">[</span><span class="va">j</span>,<span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">rmse</span><span class="op">(</span><span class="va">resid</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.859</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This improves accuracy beyond the regularized user + movie effects model from <a href="regularization.html" class="quarto-xref"><span>Chapter 24</span></a>. It illustrates, in simplified form, how the Netflix Prize winners improved prediction: by combining regularization with a latent factor model that learns hidden structure in user–movie interactions.</p>
<p>Importantly, this improvement is achieved without tuning the penalty terms <span class="math inline">\(\lambda_1\)</span> and <span class="math inline">\(\lambda_2\)</span>, the number of latent factors <span class="math inline">\(K\)</span>, or other model settings discussed next.</p>
</section><section id="visualizing-factors" class="level3"><h3 class="anchored" data-anchor-id="visualizing-factors">Visualizing factors</h3>
<p>Examining the estimated movie factors <span class="math inline">\(\mathbf{q}_k\)</span> reveals that they are interpretable.</p>
<p>The estimates for these factors are contained in <code>fit$q</code>. Because some movies do not have enough ratings to stably estimate latent factors, the <code>fit_recommender_model</code> function excludes these movies from the estimation. We therefore obtain the estimated movie factors <span class="math inline">\(\mathbf{q}_k\)</span> using:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">factors</span> <span class="op">&lt;-</span> <span class="va">fit</span><span class="op">$</span><span class="va">q</span><span class="op">[</span><span class="va">fit</span><span class="op">$</span><span class="va">n_item</span> <span class="op">&gt;=</span> <span class="va">fit</span><span class="op">$</span><span class="va">min_ratings</span>,<span class="op">]</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To make interpretation easier, we replace the row names (which are movie IDs) with movie titles:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">factors</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">movielens</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/match.html">match</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">factors</span><span class="op">)</span>, <span class="va">movieId</span><span class="op">)</span><span class="op">]</span><span class="op">$</span><span class="va">title</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Plotting the first two factors reveals several insights. First note that the six movies of our earlier example are highlighted in blue: we can see that these two factors start to explain the correlations we saw earlier, with mob films clustering together, romance films far from these, and the Al Pacino being somewhere in between:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="latent-factor-models_files/figure-html/movies-pca-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:95.0%"></p>
</figure>
</div>
</div>
</div>
<p>Looking at the movies with the most extreme factor values (red) provides a clear interpreation for the factors.</p>
<p>The first factor separates iconic dark classics</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sort.html">sort</a></span><span class="op">(</span><span class="va">factors</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>, decreasing <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "2001: A Space Odyssey"                                               </span></span>
<span><span class="co">#&gt; [2] "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb"</span></span>
<span><span class="co">#&gt; [3] "Clockwork Orange, A"                                                 </span></span>
<span><span class="co">#&gt; [4] "Taxi Driver"                                                         </span></span>
<span><span class="co">#&gt; [5] "Silence of the Lambs, The"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>from Hollywood blockbusters</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sort.html">sort</a></span><span class="op">(</span><span class="va">factors</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "Armageddon"                               </span></span>
<span><span class="co">#&gt; [2] "Pearl Harbor"                             </span></span>
<span><span class="co">#&gt; [3] "Con Air"                                  </span></span>
<span><span class="co">#&gt; [4] "Star Wars: Episode I - The Phantom Menace"</span></span>
<span><span class="co">#&gt; [5] "Mission: Impossible II"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The second factor separates weird cult movies</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sort.html">sort</a></span><span class="op">(</span><span class="va">factors</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>, decreasing <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "Showgirls"         "Scary Movie"       "Leaving Las Vegas"</span></span>
<span><span class="co">#&gt; [4] "Dogma"             "Rosemary's Baby"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>from big-budget epic historical and fantasy sagas</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sort.html">sort</a></span><span class="op">(</span><span class="va">factors</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "Lord of the Rings: The Two Towers, The"            </span></span>
<span><span class="co">#&gt; [2] "Lord of the Rings: The Return of the King, The"    </span></span>
<span><span class="co">#&gt; [3] "Lord of the Rings: The Fellowship of the Ring, The"</span></span>
<span><span class="co">#&gt; [4] "Dances with Wolves"                                </span></span>
<span><span class="co">#&gt; [5] "Matrix, The"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>These results demonstrate that the latent factors capture meaningful distinctions in film genres and styles, showing how latent factor models can uncover interpretable structure from sparse rating data.</p>
</section><section id="practical-considerations" class="level3"><h3 class="anchored" data-anchor-id="practical-considerations">Practical considerations</h3>
<p>The <code>fit_recommender_model</code> function includes several adjustable parameters:</p>
<ul>
<li><p>Penalty terms: by default, <span class="math inline">\(\lambda_1 = 0.00005\)</span> and <span class="math inline">\(\lambda_2 = 0.0001\)</span>. A grid search, as in <a href="regularization.html#sec-selecting-penalty-term" class="quarto-xref"><span>Section 24.3</span></a>, can identify better choices.</p></li>
<li><p>Number of latent factors: the default is <span class="math inline">\(K = 8\)</span>, but this may not be optimal. If <span class="math inline">\(K\)</span> is too small, the model may miss structure. If <span class="math inline">\(K\)</span> is too large, the model risks overfitting and instability.</p></li>
<li><p>Minimum ratings per movie: the function only estimates latent factors for movies with at least 20 ratings. This helps avoid unstable estimates of the <span class="math inline">\(q\)</span> vectors. However, 20 may be too high, or too low, depending on the dataset.</p></li>
<li><p>Convergence tolerance: the default stopping rule requires model improvement below <code>reltol</code>. Decreasing the tolerance will make results better, but increasing the tolerance often speeds up computation with little loss in accuracy.</p></li>
</ul>
<p>Further improvements can be made by adding more predictors, such as rating timestamps or movie genres.</p>
<p>Finally, the winning team’s breakthrough came from recognizing that missing ratings are informative. Users tend to avoid movies they expect to dislike, meaning that the absence of a rating is not random. By modeling this structure, they achieved state-of-the-art performance that ultimately led to victory.</p>
</section></section><section id="singular-value-decomposition" class="level2" data-number="25.4"><h2 data-number="25.4" class="anchored" data-anchor-id="singular-value-decomposition">
<span class="header-section-number">25.4</span> Singular Value Decomposition</h2>
<p>A related technique often used in latent factor analysis is the Singular Value Decomposition (SVD). It states any <span class="math inline">\(N \times p\)</span> matrix can be written:</p>
<p><span class="math display">\[
\mathbf{Y} = \mathbf{U}\mathbf{D}\mathbf{V}^\top
\]</span></p>
<p>where <span class="math inline">\(\mathbf{U}\)</span> is an orthogonal <span class="math inline">\(N \times p\)</span> matrix, <span class="math inline">\(\mathbf{V}\)</span> an orthogonal <span class="math inline">\(p \times p\)</span> matrix, and <span class="math inline">\(\mathbf{D}\)</span> diagonal with <span class="math inline">\(d_{1,1} \geq d_{2,2} \geq \dots \geq d_{p,p}\)</span>. SVD is connected to PCA because <span class="math inline">\(\mathbf{V}\)</span> provides the rotations for the principal components, while <span class="math inline">\(\mathbf{U}\mathbf{D}\)</span> are the principal components themselves. Squaring the diagonal entries of <span class="math inline">\(\mathbf{D}\)</span> gives the sums of squares:</p>
<p><span class="math display">\[
\mathbf{U}^\top \mathbf{D} \mathbf{U} = \mathbf{D}^2
\]</span></p>
<p>In R, we can compute the SVD with <code>svd</code> and confirm its relationship to PCA:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1000</span><span class="op">)</span>, <span class="fl">100</span>, <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">pca</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/prcomp.html">prcomp</a></span><span class="op">(</span><span class="va">x</span>, center <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">s</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/svd.html">svd</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/all.equal.html">all.equal</a></span><span class="op">(</span><span class="va">pca</span><span class="op">$</span><span class="va">rotation</span>, <span class="va">s</span><span class="op">$</span><span class="va">v</span>, check.attributes <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/all.equal.html">all.equal</a></span><span class="op">(</span><span class="va">pca</span><span class="op">$</span><span class="va">sdev</span><span class="op">^</span><span class="fl">2</span>, <span class="va">s</span><span class="op">$</span><span class="va">d</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/all.equal.html">all.equal</a></span><span class="op">(</span><span class="va">pca</span><span class="op">$</span><span class="va">x</span>, <span class="va">s</span><span class="op">$</span><span class="va">u</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">s</span><span class="op">$</span><span class="va">d</span><span class="op">)</span>, check.attributes <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As an optimization, note that <code>s$u %*% diag(s$d)</code> can be written more efficiently as:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sweep.html">sweep</a></span><span class="op">(</span><span class="va">s</span><span class="op">$</span><span class="va">u</span>, <span class="fl">2</span>, <span class="va">s</span><span class="op">$</span><span class="va">d</span>, <span class="st">"*"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The Singular Value Decomposition is one of the most widely used tools in modern data analysis, appearing in fields as diverse as signal processing, genomics, image compression, natural language processing, collaborative filtering, and numerical optimization. Any time we want to reduce dimensionality, uncover hidden structure, or work with large, noisy matrices, the SVD provides a principled foundation. In fact, many of the most successful machine learning algorithms, including the latent factor methods used in the Netflix Prize, are built directly on top of it.</p>
</section><section id="exercises" class="level2" data-number="25.5"><h2 data-number="25.5" class="anchored" data-anchor-id="exercises">
<span class="header-section-number">25.5</span> Exercises</h2>
<p>1. Examine the movie names in the extreme values of factors 3, 4, 5, 6, 7, and 8. Describe any interesting patterns you observe.</p>
<p>2. Fit the recommender model with several values of</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lambdas</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html">expand.grid</a></span><span class="op">(</span>lambda_1 <span class="op">=</span> <span class="fl">10</span><span class="op">^</span><span class="op">-</span><span class="op">(</span><span class="fl">3</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span>, lambda_2 <span class="op">=</span> <span class="fl">10</span><span class="op">^</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span><span class="op">:</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Which pair gives the lowest RMSE on a validation set? Briefly explain why too little or too much penalization can hurt performance.</p>
<p>3. Fit the model with <span class="math inline">\(K = 2, 4, 8, 16, 32\)</span>. Plot validation RMSE versus <span class="math inline">\(K\)</span>. At what point do gains level off? Based on the plot, what value of <span class="math inline">\(K\)</span> would you recommend?</p>
<p>4. Using your results from Exercises 2 and 3, perform a grid search over three values of each parameter, <span class="math inline">\(\lambda_1\)</span>, <span class="math inline">\(\lambda_2\)</span>, and <span class="math inline">\(K\)</span>, for a total of <span class="math inline">\(3 \times 3 \times 3 = 27\)</span> combinations. Report the lowest RMSE.</p>
<p>5. The default model estimates movie factors only for movies with at least 20 ratings. Try thresholds of 5, 10, 20, and 50. How does the RMSE change? Which threshold seems to balance stability and coverage best?</p>
<p>6. Run the ALS algorithm with stopping rules <code>reltol = 10^-seq(1, 8, 0.5)</code>. Record the number of iterations taken and the final RMSE. Is the improvement from tighter convergence worth the additional computation?</p>
<p>In next exercises we use the singular value decomposition (SVD) to estimate latent factors in a school-performance example.</p>
<p>We simulate grades for 100 students in 24 different courses, grouped into three subject areas: Math, Science, and Arts. The columns are individual courses (for example, Calculus, Linear Algebra, Physics, Chemistry, Music Theory, Painting), labeled <code>Math_1</code>, …, <code>Math_k</code>, <code>Science_1</code>, …, <code>Science_k</code>, and <code>Arts_1</code>, …, <code>Arts_k</code>.</p>
<p>Each entry represents points above/below the overall average for that test:</p>
<ul>
<li>0 = average (C),</li>
<li>25 = very high (A+),</li>
<li>−25 = very low (F).</li>
</ul>
<p>We assume the following model holds:</p>
<p><span class="math display">\[
Y_{ij} = \mu_{ij} + \varepsilon_{ij}
\]</span> with <span class="math inline">\(\mu_{ij}\)</span> the expected grade for student <span class="math inline">\(i\)</span> in class <span class="math inline">\(j\)</span> and <span class="math inline">\(\varepsilon_{ij}\)</span> random variation due to random chance in answering exam questions (guessing or dumb mistakes, for example). We assume the <span class="math inline">\(\varepsilon_{ij}\)</span> are independent from each other. We will simulated data with:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1987</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100</span>; <span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">8</span></span>
<span><span class="va">s</span> <span class="op">&lt;-</span> <span class="fl">64</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">.85</span>, <span class="fl">.5</span>,</span>
<span>                 <span class="fl">.85</span>, <span class="fl">1</span>, <span class="fl">.5</span>,</span>
<span>                 <span class="fl">.5</span>, <span class="fl">.5</span>, <span class="fl">1</span><span class="op">)</span>, <span class="fl">3</span>, <span class="fl">3</span><span class="op">)</span> </span>
<span><span class="va">m</span> <span class="op">&lt;-</span> <span class="fu">MASS</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html">mvrnorm</a></span><span class="op">(</span><span class="va">n</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">3</span><span class="op">)</span>, <span class="va">s</span><span class="op">)</span></span>
<span><span class="va">m</span> <span class="op">&lt;-</span> <span class="va">m</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/order.html">order</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowMeans</a></span><span class="op">(</span><span class="va">m</span><span class="op">)</span>, decreasing <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/kronecker.html">%x%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">k</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">m</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">k</span> <span class="op">*</span> <span class="fl">3</span>, <span class="fl">0</span>, <span class="fl">3</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">k</span> <span class="op">*</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Math"</span>, <span class="st">"Science"</span>, <span class="st">"Arts"</span><span class="op">)</span>, each <span class="op">=</span> <span class="va">k</span><span class="op">)</span>, <span class="fl">1</span><span class="op">:</span><span class="va">k</span>, sep <span class="op">=</span> <span class="st">"_"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We want to summarize these 24 test scores per student as simply as possible. Are students equally good in all subjects, or do we see patterns? Does being strong in one subject predict being strong in another? How can SVD help us see this structure?</p>
<p>We will show that just three pairs of vectors can explain much of the variation in this <span class="math inline">\(100 \times 24\)</span> matrix.</p>
<p>First define a helper function to visualize matrices:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">nice_image</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">zlim</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="va">cex.axis</span> <span class="op">=</span> <span class="fl">0.5</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">cols</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">rows</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/image.html">image</a></span><span class="op">(</span><span class="va">cols</span>, <span class="va">rows</span>, <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/rev.html">rev</a></span><span class="op">(</span><span class="va">rows</span><span class="op">)</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span><span class="op">)</span>,</span>
<span>        col  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rev.html">rev</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/grDevices/colorRamp.html">colorRampPalette</a></span><span class="op">(</span><span class="fu">RColorBrewer</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/RColorBrewer/man/ColorBrewer.html">brewer.pal</a></span><span class="op">(</span><span class="fl">9</span>, <span class="st">"RdBu"</span><span class="op">)</span><span class="op">)</span><span class="op">(</span><span class="fl">500</span><span class="op">)</span><span class="op">)</span>,</span>
<span>        xaxt <span class="op">=</span> <span class="st">"n"</span>, yaxt <span class="op">=</span> <span class="st">"n"</span>, xlab <span class="op">=</span> <span class="st">""</span>, ylab <span class="op">=</span> <span class="st">""</span>,</span>
<span>        zlim <span class="op">=</span> <span class="va">zlim</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>h <span class="op">=</span> <span class="va">rows</span> <span class="op">+</span> <span class="fl">0.5</span>, v <span class="op">=</span> <span class="va">cols</span> <span class="op">+</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/axis.html">axis</a></span><span class="op">(</span><span class="fl">1</span>, at <span class="op">=</span> <span class="va">cols</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, las <span class="op">=</span> <span class="fl">2</span>, cex.axis <span class="op">=</span> <span class="va">cex.axis</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>7. Use <code>nice_image(y)</code> to visualize the 24 test scores for the 100 students. Which of the following best describes what you see?</p>
<ol type="a">
<li>The test scores are all independent of each other.</li>
<li>The strongest students appear at the top of the image, and the 24 tests seem to group into three subject blocks.</li>
<li>Students who are good at math are clearly bad at science.</li>
<li>Students who are good at math are clearly bad at the arts.</li>
</ol>
<p>8. Now look at the correlation matrix of the 24 tests:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">nice_image</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, zlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/axis.html">axis</a></span><span class="op">(</span>side <span class="op">=</span> <span class="fl">2</span>, at <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rev.html">rev</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span>, las <span class="op">=</span> <span class="fl">2</span>, cex.axis <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Which option best describes the correlation pattern?</p>
<ol type="a">
<li>The test scores are independent.</li>
<li>Math and Science are highly correlated, but Arts is not correlated with anything.</li>
<li>Tests within the same subject are correlated, but there is no correlation between subjects.</li>
<li>There is correlation among all tests, with stronger correlation within each subject and stronger correlation between Math and Science than between either and Arts.</li>
</ol>
<p>9. First compute the total sum of squares in <code>y</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">tss_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colSums</a></span><span class="op">(</span><span class="va">y</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now compute the SVD</p>
<p><span class="math display">\[
\mathbf{Y} = \mathbf{U}\mathbf{D}\mathbf{V}^\top.
\]</span></p>
<p>Use the SVD to verify in R that:</p>
<ul>
<li>The total sum of squares of all entries in <span class="math inline">\(\mathbf{Y}\mathbf{V} = \mathbf{U}\mathbf{D}\)</span> is the same as in <span class="math inline">\(\mathbf{Y}\)</span>.</li>
<li>The sum of the squared singular values (the diagonal entries of <span class="math inline">\(\mathbf{D}\)</span>) is also equal to <code>tss_y</code>.</li>
</ul>
<p>Check these equalities in R and make sure you understand <em>why</em> they must hold (hint: <span class="math inline">\(\mathbf{V}\)</span> is orthogonal and SVD preserves total sum of squares).</p>
<p>10. Let <span class="math inline">\(\mathbf{Z} = \mathbf{Y}\mathbf{V} = \mathbf{U}\mathbf{D}\)</span>.</p>
<ul>
<li>Plot the square root of the sum of squares of each column of <span class="math inline">\(\mathbf{Y}\)</span> versus the column index.</li>
<li>On the same scale, plot the square root of the sum of squares of each column of the columns of <span class="math inline">\(\mathbf{Z}\)</span>.</li>
</ul>
<p>Comment on what you see. Does the variation across columns become more concentrated in the first few columns of <span class="math inline">\(\mathbf{Z}\)</span>?</p>
<p>11. In exercise 10 you computed the column sums of squares of <span class="math inline">\(\mathbf{Z} = \mathbf{Y}\mathbf{V} = \mathbf{U}\mathbf{D}\)</span> using <code>colSums</code>. However, we actually already know these numbers from the SVD:</p>
<ul>
<li>Show in R that the squared singular values <span class="math inline">\((d_{kk}^2)\)</span> are equal to the column sums of squares of <span class="math inline">\(\mathbf{Z}\)</span>.</li>
<li>Confirm this numerically by plotting the square root of the column sums of squares of <span class="math inline">\(\mathbf{Z}\)</span> versus the diagonal entries of <span class="math inline">\(\mathbf{D}\)</span>.</li>
</ul>
<p>12. The columns of <span class="math inline">\(\mathbf{Z} = \mathbf{Y}\mathbf{V} = \mathbf{U}\mathbf{D}\)</span> are the principal components (PCs) of <span class="math inline">\(\mathbf{Y}\)</span>. The diagonal of <span class="math inline">\(\mathbf{D}\)</span> tells us how much variability each PC explains.</p>
<p>Compute the SVD and plot the percentage of variance explained by each PC:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">s</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/svd.html">svd</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, <span class="va">s</span><span class="op">$</span><span class="va">d</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">s</span><span class="op">$</span><span class="va">d</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">*</span><span class="fl">100</span>, xlab <span class="op">=</span> <span class="st">"PC"</span>, ylab <span class="op">=</span> <span class="st">"Variance explained (%)"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You should see that the first PC explains over 60% of the variability. Compare the first PC to each student’s average grade:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pc1</span> <span class="op">&lt;-</span> <span class="va">s</span><span class="op">$</span><span class="va">u</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span><span class="op">*</span><span class="va">s</span><span class="op">$</span><span class="va">d</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowMeans</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, <span class="va">pc1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>How would you interpret the first PC in plain language? (Remember the sign is arbitrary, so high PC1 can correspond to strong student or weak student, depending on sign.)</p>
<p>13. The SVD can be written as</p>
<p><span class="math display">\[
\mathbf{Y} = \mathbf{u}_1 d_{1,1} \mathbf{v}_1^\top
   + \mathbf{u}_2 d_{2,2} \mathbf{v}_2^\top
   + \dots
   + \mathbf{u}_p d_{p,p} \mathbf{v}_p^\top,
\]</span></p>
<p>where <span class="math inline">\(\mathbf{u}_k\)</span> is the <span class="math inline">\(k\)</span>-th column of <span class="math inline">\(\mathbf{U}\)</span>, <span class="math inline">\(d_{k,k}\)</span> is the <span class="math inline">\(k\)</span>-th diagonal entry of <span class="math inline">\(\mathbf{D}\)</span>, and <span class="math inline">\(\mathbf{v}_k\)</span> is the <span class="math inline">\(k\)</span>-th column of <span class="math inline">\(\mathbf{V}\)</span>.</p>
<p>Approximate all student grades <span class="math inline">\(\mu_{ij}\)</span> using only the first term:</p>
<p><span class="math display">\[
\hat{\mu}_{ij} = \mathbf{u}_1 d_{1,1} \mathbf{v}_1^\top.
\]</span> Compute the residual matrix <span class="math inline">\(\mathbf{r} = \mathbf{y} - \mathbf{u}_1 d_{1,1} \mathbf{v}_1^\top\)</span>, and visualize the residuals and their correlations with <code>nice_image</code>. Do you still see subject-level correlation structure in the residuals?</p>
<p>14. Now approximate grades using the first two components:</p>
<p><span class="math display">\[
\hat{\mu}_{ij} = \sum_{k=1}^2 \mathbf{u}_k d_{k,k} \mathbf{v}_k^\top.
\]</span></p>
<p>and repeat exploratory plots generated in exercise 13. Has most of the correlation structure disappeared, or is there still visible within-subject pattern?</p>
<p>15. Now repeat exercise 14 but using the first three components:</p>
<p><span class="math display">\[
\hat{\mu}_{ij} = \sum_{k=1}^3 \mathbf{u}_k d_{k,k} \mathbf{v}_k^\top.
\]</span></p>
<p>Is the correlation now essentially gone? How many factors does it seem we need to capture the main structure <span class="math inline">\(\mu_{ij}\)</span> for these 24 courses?</p>
<p>16. Finally, inspect the first three right singular vectors (the columns of <span class="math inline">\(\mathbf{V}\)</span>):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">v</span> <span class="op">&lt;-</span> <span class="va">s</span><span class="op">$</span><span class="va">v</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">v</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span><span class="fu">nice_image</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">v</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Each row corresponds to a course (for example, <code>Math_1</code>, <code>Science_3</code>, <code>Arts_5</code>), and each column corresponds to one factor (PC1, PC2, PC3). How would you interpret the first three columns of <span class="math inline">\(\mathbf{V}\)</span>? Write a short interpretation for each of the three factors in plain language.</p>
<p>17. Based on the patterns see in exercise 16, how would you interpret the values <span class="math inline">\(u_{i1}\)</span>, , <span class="math inline">\(u_{ip}\)</span> for student <span class="math inline">\(i\)</span>:</p>
<ul>
<li>Is one roughly quantifying <em>overall academic strength</em>?</li>
<li>Is one quantifying how much better the student is at <em>STEM vs.&nbsp;Arts</em>?</li>
<li>Is another quantifying how much better at <em>Math vs.&nbsp;Science</em>?</li>
<li>Are some of them just random noise?</li>
</ul>


</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("http:\/\/rafalab\.dfci\.harvard\.edu\/dsbook-part-2");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../highdim/regularization.html" class="pagination-link" aria-label="Regularization">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Regularization</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../highdim/reading-highdim.html" class="pagination-link" aria-label="Recommended reading">
        <span class="nav-page-text">Recommended reading</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>Introduction to Data Science was written by Rafael A. Irizarry</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/rafalab/dsbook-part-2/blob/main/highdim/latent-factor-models.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/rafalab/dsbook-part-2/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


</body></html>