<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Rafael A. Irizarry">
<title>29&nbsp; Resampling methods – Introduction to Data Science</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../ml/algorithms.html" rel="next">
<link href="../ml/smoothing.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-314d552717907458410b1a40a915f399.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../ml/intro-ml.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="../ml/resampling-methods.html"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Resampling methods</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Introduction to Data Science</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/rafalab/dsbook-part-2" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../summaries/intro-summaries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Summary statistics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../summaries/distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../summaries/robust-summaries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Robust summaries</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../prob/intro-to-prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob/discrete-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Discrete probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob/continuous-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Continuous probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob/random-variables-sampling-models-clt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Foundations of statistical inference</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../inference/intro-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistical inference</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/parameters-estimates.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Parameters and Estimates</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/clt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Central Limit Theorem</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/confidence-intervals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Confidence intervals</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Data-driven models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Bayesian statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/hierarchical-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Hierarchichal Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/hypothesis-testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Hypothesis testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/bootstrap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Bootstrap</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../linear-models/intro-to-linear-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear Models</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/measurement-error-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Measurement error models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/treatment-effect-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Treatment effect models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/association-tests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Association tests</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/association-not-causation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Association is not causation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/multivariable-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Multivariable Regression</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../highdim/intro-highdim.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">High dimensional data</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/matrices-in-R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Matrices in R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/linear-algebra.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Applied Linear Algebra</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/dimension-reduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Dimension reduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/regularization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Regularization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/latent-factor-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Latent factor models</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../ml/intro-ml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/notation-and-terminology.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Notation and terminology</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/evaluation-metrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Evaluation metrics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/conditionals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Conditional probabilities and expectations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/smoothing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Smoothing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/resampling-methods.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Resampling methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/algorithms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Examples of algorithms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/ml-in-practice.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Machine learning in practice</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#sec-knn-cv-intro" id="toc-sec-knn-cv-intro" class="nav-link active" data-scroll-target="#sec-knn-cv-intro"><span class="header-section-number">29.1</span> Motivation with k-nearest neighbors</a></li>
  <li><a href="#over-training" id="toc-over-training" class="nav-link" data-scroll-target="#over-training"><span class="header-section-number">29.2</span> Over-training</a></li>
  <li><a href="#over-smoothing" id="toc-over-smoothing" class="nav-link" data-scroll-target="#over-smoothing"><span class="header-section-number">29.3</span> Over-smoothing</a></li>
  <li><a href="#tuning-parameter" id="toc-tuning-parameter" class="nav-link" data-scroll-target="#tuning-parameter"><span class="header-section-number">29.4</span> Tuning parameter</a></li>
  <li><a href="#mathematical-description-of-resampling-methods" id="toc-mathematical-description-of-resampling-methods" class="nav-link" data-scroll-target="#mathematical-description-of-resampling-methods"><span class="header-section-number">29.5</span> Mathematical description of resampling methods</a></li>
  <li>
<a href="#cross-validation" id="toc-cross-validation" class="nav-link" data-scroll-target="#cross-validation"><span class="header-section-number">29.6</span> Cross validation</a>
  <ul class="collapse">
<li><a href="#k-fold-cross-validation" id="toc-k-fold-cross-validation" class="nav-link" data-scroll-target="#k-fold-cross-validation"><span class="header-section-number">29.6.1</span> K-fold cross validation</a></li>
  <li><a href="#how-many-folds" id="toc-how-many-folds" class="nav-link" data-scroll-target="#how-many-folds"><span class="header-section-number">29.6.2</span> How many folds?</a></li>
  <li><a href="#estimate-mse-of-our-optimized-algorithm" id="toc-estimate-mse-of-our-optimized-algorithm" class="nav-link" data-scroll-target="#estimate-mse-of-our-optimized-algorithm"><span class="header-section-number">29.6.3</span> Estimate MSE of our optimized algorithm</a></li>
  </ul>
</li>
  <li>
<a href="#boostrap-resampling" id="toc-boostrap-resampling" class="nav-link" data-scroll-target="#boostrap-resampling"><span class="header-section-number">29.7</span> Boostrap resampling</a>
  <ul class="collapse">
<li><a href="#sec-mse-estimates" id="toc-sec-mse-estimates" class="nav-link" data-scroll-target="#sec-mse-estimates"><span class="header-section-number">29.7.1</span> Comparison of MSE estimates</a></li>
  </ul>
</li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">29.8</span> Exercises</a></li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/rafalab/dsbook-part-2/blob/main/ml/resampling-methods.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/rafalab/dsbook-part-2/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../ml/intro-ml.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="../ml/resampling-methods.html"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Resampling methods</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title"><span id="sec-cross-validation" class="quarto-section-identifier"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Resampling methods</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><p>In this chapter, we introduce resampling, one of the most important ideas in machine learning. Here we focus on the conceptual and mathematical aspects. We will describe how to implement resampling methods in practice with the <strong>caret</strong> package later in <a href="ml-in-practice.html#sec-caret" class="quarto-xref"><span>Section 32.1</span></a>. To motivate the concept, we will use the two predictor digits data presented in <a href="smoothing.html#sec-two-or-seven" class="quarto-xref"><span>Section 28.1</span></a> and introduce k-nearest neighbors (kNN), to demonstrate the ideas.</p>
<section id="sec-knn-cv-intro" class="level2" data-number="29.1"><h2 data-number="29.1" class="anchored" data-anchor-id="sec-knn-cv-intro">
<span class="header-section-number">29.1</span> Motivation with k-nearest neighbors</h2>
<p>We are interested in estimating the conditional probability function:</p>
<p><span class="math display">\[
p(\mathbf{x}) = \mathrm{Pr}(Y = 1 \mid X_1 = x_1 , X_2 = x_2).
\]</span></p>
<p>as defined in <a href="smoothing.html#sec-smoothing-ml-connection" class="quarto-xref"><span>Section 28.6</span></a>.</p>
<p>With k-nearest neighbors (kNN) we estimate <span class="math inline">\(p(\mathbf{x})\)</span> in a similar way to bin smoothing. First, we define the distance between all observations based on the features. Then, for any point <span class="math inline">\(\mathbf{x}_0\)</span>, we estimate <span class="math inline">\(p(\mathbf{x})\)</span> by identifying the <span class="math inline">\(k\)</span> nearest points to <span class="math inline">\(\mathbf{x}_0\)</span> and afterwards taking an average of the <span class="math inline">\(y\)</span>s associated with these points. We refer to the set of points used to compute the average as the <em>neighborhood</em>.</p>
<p>Due to the connection we described earlier between conditional expectations and conditional probabilities, this gives us <span class="math inline">\(\hat{p}(\mathbf{x}_0)\)</span>, just like the bin smoother gave us an estimate of a trend. As with bin smoothers, we can control the flexibility of our estimate through the <span class="math inline">\(k\)</span> parameter: larger <span class="math inline">\(k\)</span>s result in smoother estimates, while smaller <span class="math inline">\(k\)</span>s result in more flexible and wiggly estimates.</p>
<p>To implement the algorithm, we can use the <code>knn3</code> function from the <strong>caret</strong> package. Looking at the help file for this package, we see that we can call it in one of two ways. We will use the first way in which we specify a <em>formula</em> and a data frame. The data frame contains all the data to be used. The formula has the form <code>outcome ~ predictor_1 + predictor_2 + predictor_3</code> and so on. Therefore, we type <code>y ~ x_1 + x_2</code>. If we are going to use variables in the data frame, we can use the <code>.</code> like this <code>y ~ .</code>. We also need to pick <span class="math inline">\(k\)</span>, which is set to <code>k = 5</code> by default. The final call looks like this:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">dslabs</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/topepo/caret/">caret</a></span><span class="op">)</span></span>
<span><span class="va">knn_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/knn3.html">knn3</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">mnist_27</span><span class="op">$</span><span class="va">train</span>, k <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In this case, since our dataset is balanced and we care just as much about sensitivity as we do about specificity, we will use accuracy to quantify performance.</p>
<p>The <code>predict</code> function for <code>knn3</code> produces a probability for each class. We can keep the probability of being a 7 as the estimate <span class="math inline">\(\hat{p}(\mathbf{x})\)</span> using <code>type = "prob"</code>. Here we obtain the actual prediction using <code>type = "class"</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">y_hat_knn</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">knn_fit</span>, <span class="va">mnist_27</span><span class="op">$</span><span class="va">test</span>, type <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span><span class="va">y_hat_knn</span>, <span class="va">mnist_27</span><span class="op">$</span><span class="va">test</span><span class="op">$</span><span class="va">y</span><span class="op">)</span><span class="op">$</span><span class="va">overall</span><span class="op">[</span><span class="st">"Accuracy"</span><span class="op">]</span></span>
<span><span class="co">#&gt; Accuracy </span></span>
<span><span class="co">#&gt;    0.815</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We see that kNN, with the default parameter, already beats regression. To see why this is the case, we plot <span class="math inline">\(\hat{p}(\mathbf{x})\)</span> and compare it to the true conditional probability <span class="math inline">\(p(\mathbf{x})\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="resampling-methods_files/figure-html/knn-fit-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>We see that kNN adapts better to the non-linear shape of <span class="math inline">\(p(\mathbf{x})\)</span>. However, our estimate has some islands of blue in the red area, which intuitively does not make much sense. We notice that we have higher accuracy in the train set compared to the test set:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">y_hat_knn</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">knn_fit</span>, <span class="va">mnist_27</span><span class="op">$</span><span class="va">train</span>, type <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span><span class="va">y_hat_knn</span>, <span class="va">mnist_27</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">y</span><span class="op">)</span><span class="op">$</span><span class="va">overall</span><span class="op">[</span><span class="st">"Accuracy"</span><span class="op">]</span></span>
<span><span class="co">#&gt; Accuracy </span></span>
<span><span class="co">#&gt;    0.856</span></span>
<span></span>
<span><span class="va">y_hat_knn</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">knn_fit</span>, <span class="va">mnist_27</span><span class="op">$</span><span class="va">test</span>, type <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span><span class="va">y_hat_knn</span>, <span class="va">mnist_27</span><span class="op">$</span><span class="va">test</span><span class="op">$</span><span class="va">y</span><span class="op">)</span><span class="op">$</span><span class="va">overall</span><span class="op">[</span><span class="st">"Accuracy"</span><span class="op">]</span></span>
<span><span class="co">#&gt; Accuracy </span></span>
<span><span class="co">#&gt;    0.815</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This is due to what we call <em>over-training</em>.</p>
</section><section id="over-training" class="level2" data-number="29.2"><h2 data-number="29.2" class="anchored" data-anchor-id="over-training">
<span class="header-section-number">29.2</span> Over-training</h2>
<p>With kNN, over-training is at its worst when we set <span class="math inline">\(k = 1\)</span>. With <span class="math inline">\(k = 1\)</span>, the estimate for each <span class="math inline">\(\mathbf{x}\)</span> in the training set is obtained with just the <span class="math inline">\(y\)</span> corresponding to that point. In this case, if the <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are unique, we will obtain perfect accuracy in the training set because each point is used to predict itself (if the predictors are not unique and have different outcomes for at least one set of predictors, then it is impossible to predict perfectly).</p>
<p>Here we fit a kNN model with <span class="math inline">\(k = 1\)</span> and confirm we get near perfect accuracy in the training set:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">knn_fit_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/knn3.html">knn3</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">mnist_27</span><span class="op">$</span><span class="va">train</span>, k <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">y_hat_knn_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">knn_fit_1</span>, <span class="va">mnist_27</span><span class="op">$</span><span class="va">train</span>, type <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span><span class="va">y_hat_knn_1</span>, <span class="va">mnist_27</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">y</span><span class="op">)</span><span class="op">$</span><span class="va">overall</span><span class="op">[[</span><span class="st">"Accuracy"</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="co">#&gt; [1] 0.994</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>But in the test set, accuracy is actually worse than what we obtained with regression:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">y_hat_knn_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">knn_fit_1</span>, <span class="va">mnist_27</span><span class="op">$</span><span class="va">test</span>, type <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span><span class="va">y_hat_knn_1</span>, <span class="va">mnist_27</span><span class="op">$</span><span class="va">test</span><span class="op">$</span><span class="va">y</span><span class="op">)</span><span class="op">$</span><span class="va">overall</span><span class="op">[</span><span class="st">"Accuracy"</span><span class="op">]</span></span>
<span><span class="co">#&gt; Accuracy </span></span>
<span><span class="co">#&gt;     0.81</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can see the over-fitting problem by plotting the decision rule boundaries produced by <span class="math inline">\(\hat{p}(\mathbf{x})\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="resampling-methods_files/figure-html/knn-1-overfit-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>The estimate <span class="math inline">\(\hat{p}(\mathbf{x})\)</span> follows the training data too closely (left). You can see that, in the training set, boundaries have been drawn to perfectly surround a single red point in a sea of blue. Because most points <span class="math inline">\(\mathbf{x}\)</span> are unique, the prediction is either 1 or 0 and the prediction for that point is the associated label. However, once we introduce the test set (right), we see that many of these small islands now have the opposite color and we end up making several incorrect predictions.</p>
</section><section id="over-smoothing" class="level2" data-number="29.3"><h2 data-number="29.3" class="anchored" data-anchor-id="over-smoothing">
<span class="header-section-number">29.3</span> Over-smoothing</h2>
<p>Although not as badly as with <span class="math inline">\(k=1\)</span>, we saw that with <span class="math inline">\(k = 5\)</span> we also over-trained. Hence, we should consider a larger <span class="math inline">\(k\)</span>. Let’s try, as an example, a much larger number: <span class="math inline">\(k = 401\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">knn_fit_401</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/knn3.html">knn3</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">mnist_27</span><span class="op">$</span><span class="va">train</span>, k <span class="op">=</span> <span class="fl">401</span><span class="op">)</span></span>
<span><span class="va">y_hat_knn_401</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">knn_fit_401</span>, <span class="va">mnist_27</span><span class="op">$</span><span class="va">test</span>, type <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span><span class="va">y_hat_knn_401</span>, <span class="va">mnist_27</span><span class="op">$</span><span class="va">test</span><span class="op">$</span><span class="va">y</span><span class="op">)</span><span class="op">$</span><span class="va">overall</span><span class="op">[</span><span class="st">"Accuracy"</span><span class="op">]</span></span>
<span><span class="co">#&gt; Accuracy </span></span>
<span><span class="co">#&gt;     0.76</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The estimate turns out to be similar to the one obtained with regression:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="resampling-methods_files/figure-html/mnist-27-glm-est-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>In this case, <span class="math inline">\(k\)</span> is so large that it does not permit enough flexibility. We call this <em>over-smoothing</em>.</p>
</section><section id="tuning-parameter" class="level2" data-number="29.4"><h2 data-number="29.4" class="anchored" data-anchor-id="tuning-parameter">
<span class="header-section-number">29.4</span> Tuning parameter</h2>
<p>It is very common for machine learning algorithms to require that we set one or more values <em>before</em> fitting the model. A simple example is the choice of <span class="math inline">\(k\)</span> in k-Nearest Neighbors (kNN). In <a href="algorithms.html" class="quarto-xref"><span>Chapter 30</span></a>, we will see additional examples. These values are referred to as <em>tuning parameters</em>, and an important part of applying machine learning in practice is choosing them, often called <em>tuning the model</em>.</p>
<p>So how do we pick tuning parameters? For instance, how do we decide on the best <span class="math inline">\(k\)</span> in kNN? In principle, we want the value of <span class="math inline">\(k\)</span> that maximizes accuracy or, equivalently, minimizes the expected MSE as defined in <a href="evaluation-metrics.html#sec-mse" class="quarto-xref"><span>Section 26.8</span></a>. The challenge is that we do not know the true expected error. The goal of <em>resampling methods</em> is to estimate this error for any given algorithm and set of tuning parameters, such as <span class="math inline">\(k\)</span>.</p>
<p>To see why we need resampling, let’s repeat what we did earlier: compare training and test set accuracy, but now for a range of <span class="math inline">\(k\)</span> values. We can then plot the accuracy estimates for each choice of <span class="math inline">\(k\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="resampling-methods_files/figure-html/accuracy-vs-k-knn-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>First, note that the estimate obtained from the training set is generally more optimistic, higher accuracy, than the estimate from the test set, with the gap being larger for smaller values of <span class="math inline">\(k\)</span>. This is a classic symptom of <em>overfitting</em>.</p>
<p>So should we simply pick the <span class="math inline">\(k\)</span> that maximizes accuracy and report this value? There are two key problems with this approach:</p>
<ol type="1">
<li><p>The accuracy-versus-<span class="math inline">\(k\)</span> plot is quite jagged. We do not expect small changes in <span class="math inline">\(k\)</span> to cause large swings in accuracy or MSE. The jaggedness arises because the accuracy is estimated from a finite sample, making it a random variable.</p></li>
<li><p>Although we used the test set to estimate accuracy for each <span class="math inline">\(k\)</span>, we also used the <em>same</em> test set to select the best <span class="math inline">\(k\)</span>. As a result, the reported minimum test set error is overly optimistic and will not generalize to new, unseen data.</p></li>
</ol>
<p><em>Resampling methods</em> provide a principled solution to both problems by reducing variability and ensuring that test data are not used twice—once for evaluation and again for tuning.</p>
</section><section id="mathematical-description-of-resampling-methods" class="level2" data-number="29.5"><h2 data-number="29.5" class="anchored" data-anchor-id="mathematical-description-of-resampling-methods">
<span class="header-section-number">29.5</span> Mathematical description of resampling methods</h2>
<p>In the previous section, we introduced kNN as an example to motivate the topic of this chapter. In this particular case, there is just one parameter, <span class="math inline">\(k\)</span>, that affects the performance of the algorithm. However, in general, machine algorithms may have multiple parameters so we use the notation <span class="math inline">\(\lambda\)</span> to represent any set of parameters needed to define a machine learning algorithm. We also introduce notation to distinguish the predictions you get with each set of parameters with <span class="math inline">\(\hat{y}(\lambda)\)</span> and the MSE for this choice with <span class="math inline">\(\text{MSE}(\lambda)\)</span>. Our goal is to find the <span class="math inline">\(\lambda\)</span> that minimizes <span class="math inline">\(\text{MSE}(\lambda)\)</span>. Resampling methods help us estimate <span class="math inline">\(\text{MSE}(\lambda)\)</span>.</p>
<p>An intuitive first attempt is the apparent error defined in <a href="evaluation-metrics.html#sec-mse" class="quarto-xref"><span>Section 26.8</span></a> and used in the previous section:</p>
<p><span class="math display">\[
\hat{\mbox{MSE}}(\lambda) = \frac{1}{N}\sum_{i = 1}^N \left\{\hat{y}_i(\lambda) - y_i\right\}^2
\]</span></p>
<p>As noted in the previous section, this estimate is a random error, based on just one test set, with enough variability to affect the choice of the best <span class="math inline">\(\lambda\)</span> substantially.</p>
<p>Now imagine a world in which we could obtain data repeatedly, say from new random samples. We could take a very large number <span class="math inline">\(B\)</span> of new samples, split them into training and test sets, and define:</p>
<p><span class="math display">\[
\frac{1}{B} \sum_{b=1}^B \frac{1}{N}\sum_{i=1}^N \left\{\hat{y}_i^b(\lambda) - y_i^b\right\}^2
\]</span></p>
<p>with <span class="math inline">\(y_i^b\)</span> the <span class="math inline">\(i\)</span>th observation in sample <span class="math inline">\(b\)</span> and <span class="math inline">\(\hat{y}_{i}^b(\lambda)\)</span> the prediction obtained with the algorithm defined by parameter <span class="math inline">\(\lambda\)</span> and trained independently of <span class="math inline">\(y_i^b\)</span>. The law of large numbers tells us that as <span class="math inline">\(B\)</span> becomes larger, this quantity gets closer and closer to <span class="math inline">\(MSE(\lambda)\)</span>. This is of course a theoretical consideration as we rarely get access to more than one dataset for algorithm development, but the concept inspires the idea behind resampling methods.</p>
<p>The general idea is to generate a series of different random samples from the data at hand. There are several approaches to doing this, but all randomly generate several smaller datasets that are not used for training, and instead are used to estimate MSE. Next, we describe <em>cross validation</em>, one of the most widely used resampling methods.</p>
</section><section id="cross-validation" class="level2" data-number="29.6"><h2 data-number="29.6" class="anchored" data-anchor-id="cross-validation">
<span class="header-section-number">29.6</span> Cross validation</h2>
<p>Overall, we are provided a dataset (blue) and we need to build an algorithm, using this dataset, that will eventually be used in completely independent datasets (yellow) that we might not even see.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/cv-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="display: block; margin-left: auto; margin-right: auto; background-color: #000; padding:3px;" width="500"></p>
</figure>
</div>
</div>
</div>
<p>So to imitate this situation, we start by carving out a piece of our dataset and pretend it is an independent dataset: we divide the dataset into a <em>training set</em> (blue) and a <em>test set</em> (red). We will train the entirety of our algorithm, including the choice of parameter <span class="math inline">\(\lambda\)</span>, exclusively on the training set and use the test set only for evaluation purposes.</p>
<p>We usually try to select a small piece of the dataset so that we have as much data as possible to train. However, we also want the test set to be large so that we obtain a stable estimate of the MSE without fitting an impractical number of models. Typical choices are to use 10%-20% of the data for testing.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/cv-3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="display: block; margin-left: auto; margin-right: auto; background-color: #000; padding:3px;" width="500"></p>
</figure>
</div>
</div>
</div>
<p>Let’s reiterate that it is indispensable that we not use the test set at all: not for filtering out rows, not for selecting features, not for anything!</p>
<p>But then how do we optimize <span class="math inline">\(\lambda\)</span>? In cross validation, we achieve this by splitting the training set into two: the training and validation sets.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/cv-4.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="display: block; margin-left: auto; margin-right: auto; background-color: #000; padding:3px;" width="500"></p>
</figure>
</div>
</div>
</div>
<p>We will do this many times assuring that the estimates of MSE obtained in each dataset are independent from each other. There are several proposed methods for doing this. Here we describe one of these approaches, K-fold cross validation, in detail to provide the general idea used in all approaches.</p>
<section id="k-fold-cross-validation" class="level3" data-number="29.6.1"><h3 data-number="29.6.1" class="anchored" data-anchor-id="k-fold-cross-validation">
<span class="header-section-number">29.6.1</span> K-fold cross validation</h3>
<p>As a reminder, we are going to imitate the concept used when introducing this version of the MSE:</p>
<p><span class="math display">\[
\mbox{MSE}(\lambda) \approx\frac{1}{B} \sum_{b = 1}^B \frac{1}{N}\sum_{i = 1}^N \left(\hat{y}_i^b(\lambda) - y_i^b\right)^2
\]</span></p>
<p>We want to generate a dataset that can be thought of as independent random sample, and do this <span class="math inline">\(B\)</span> times. The K in K-fold cross validation, represents the number of time <span class="math inline">\(B\)</span>. In the illustrations, we are showing an example that uses <span class="math inline">\(B = 5\)</span>.</p>
<p>We will eventually end up with <span class="math inline">\(B\)</span> samples, but let’s start by describing how to construct the first: we simply pick <span class="math inline">\(M = N/B\)</span> observations at random (we round if <span class="math inline">\(M\)</span> is not a round number) and think of these as a random sample <span class="math inline">\(y_1^b, \dots, y_M^b\)</span>, with <span class="math inline">\(b = 1\)</span>. We call this the validation set.</p>
<p>Now we can fit the model in the training set, then compute the apparent error on the independent set:</p>
<p><span class="math display">\[
\hat{\mbox{MSE}}_b(\lambda) = \frac{1}{M}\sum_{i = 1}^M \left(\hat{y}_i^b(\lambda) - y_i^b\right)^2
\]</span></p>
<p>As a reminder, this is just one sample and will therefore return a noisy estimate of the true error. In K-fold cross validation, we randomly split the observations into <span class="math inline">\(B\)</span> non-overlapping sets:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/cv-5.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="display: block; margin-left: auto; margin-right: auto; background-color: #000; padding:3px;" width="500"></p>
</figure>
</div>
</div>
</div>
<p>Now we repeat the calculation above for each of these sets <span class="math inline">\(b = 1,\dots,B\)</span> and obtain <span class="math inline">\(\hat{\mbox{MSE}}_1(\lambda),\dots, \hat{\mbox{MSE}}_B(\lambda)\)</span>. Then, for our final estimate, we compute the average:</p>
<p><span class="math display">\[
\hat{\mbox{MSE}}(\lambda) = \frac{1}{B} \sum_{b = 1}^B \hat{\mbox{MSE}}_b(\lambda)
\]</span></p>
<p>and obtain an estimate of our loss. A final step would be to select the <span class="math inline">\(\lambda\)</span> that minimizes the MSE.</p>
</section><section id="how-many-folds" class="level3" data-number="29.6.2"><h3 data-number="29.6.2" class="anchored" data-anchor-id="how-many-folds">
<span class="header-section-number">29.6.2</span> How many folds?</h3>
<p>Now how do we pick the cross validation fold? Large values of <span class="math inline">\(B\)</span> are preferable because the training data better imitates the original dataset. However, larger values of <span class="math inline">\(B\)</span> will have much slower computation time: for example, 100-fold cross validation will be 10 times slower than 10-fold cross validation. For this reason, the choices of <span class="math inline">\(B = 5\)</span> and <span class="math inline">\(B = 10\)</span> are popular.</p>
<p>One way we can improve the variance of our final estimate is to take more samples. To do this, we would no longer require the training set to be partitioned into non-overlapping sets. Instead, we would just pick <span class="math inline">\(B\)</span> sets of some size at random.</p>
</section><section id="estimate-mse-of-our-optimized-algorithm" class="level3" data-number="29.6.3"><h3 data-number="29.6.3" class="anchored" data-anchor-id="estimate-mse-of-our-optimized-algorithm">
<span class="header-section-number">29.6.3</span> Estimate MSE of our optimized algorithm</h3>
<p>We have described how to use cross validation to optimize parameters. However, we now have to take into account the fact that the optimization occurred on the training data and we therefore need an estimate of our final algorithm based on data that was not used to optimize the choice. Here is where we use the test set we separated early on:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/cv-6.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="display: block; margin-left: auto; margin-right: auto; background-color: #000; padding:3px;" width="500"></p>
</figure>
</div>
</div>
</div>
<p>We can actually do cross validation again:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/cv-7.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="display: block; margin-left: auto; margin-right: auto; background-color: #000; padding:3px;" width="500"></p>
</figure>
</div>
</div>
</div>
<p>and obtain a final estimate of our expected loss. However, note that last cross validation iteration means that our entire compute time gets multiplied by <span class="math inline">\(K\)</span>. You will soon learn that fitting each algorithm takes time because we are performing many complex computations. As a result, we are always looking for ways to reduce this time. For the final evaluation, we often just use the one test set.</p>
<p>Once we are satisfied with this model and want to make it available to others, we could refit the model on the entire dataset, without changing the optimized parameters.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/cv-8.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="display: block; margin-left: auto; margin-right: auto; background-color: #000; padding:3px;" width="500"></p>
</figure>
</div>
</div>
</div>
</section></section><section id="boostrap-resampling" class="level2" data-number="29.7"><h2 data-number="29.7" class="anchored" data-anchor-id="boostrap-resampling">
<span class="header-section-number">29.7</span> Boostrap resampling</h2>
<p>Typically, cross-validation involves partitioning the original dataset into a training set to train the model and a testing set to evaluate it. With the bootstrap approach, based on the ideas described in <a href="../inference/bootstrap.html" class="quarto-xref"><span>Chapter 13</span></a>, you can create multiple different training datasets via bootstrapping. This method is sometimes called bootstrap aggregating or bagging.</p>
<p>In bootstrap resampling, we create a large number of bootstrap samples from the original training dataset. Each bootstrap sample is created by randomly selecting observations with replacement, usually the same size as the original training dataset. For each bootstrap sample, we fit the model and compute the MSE estimate on the observations not selected in the random sampling, referred to as the <em>out-of-bag observations</em>. These out-of-bag observations serve a similar role to a validation set in standard cross-validation.</p>
<p>We then average the MSEs obtained in the out-of-bag observations from each bootstrap sample to estimate the model’s performance.</p>
<p>This approach is actually the default approach in the <strong>caret</strong> package. We describe how to implement resampling methods with the <strong>caret</strong> package in the next chapter.</p>
<section id="sec-mse-estimates" class="level3" data-number="29.7.1"><h3 data-number="29.7.1" class="anchored" data-anchor-id="sec-mse-estimates">
<span class="header-section-number">29.7.1</span> Comparison of MSE estimates</h3>
<p>In <a href="#sec-knn-cv-intro" class="quarto-xref"><span>Section 29.1</span></a>, we computed an estimate of MSE based just on the provided test set (shown in red in the plot below). Here we show how the cross-validation techniques described above help reduce variability. The green curve below shows the results of applying K-fold cross validation with 10 folds, leaving out 10% of the data for validation. We can see that the variance is reduced substantially. The blue curve is the result of using 100 bootstrap samples to estimate MSE. The variability is reduced even further, but at the cost of a 10 fold increase in computation time.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="resampling-methods_files/figure-html/k-fold-versus-bootstrap-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
</section></section><section id="exercises" class="level2" data-number="29.8"><h2 data-number="29.8" class="anchored" data-anchor-id="exercises">
<span class="header-section-number">29.8</span> Exercises</h2>
<p>Generate a set of random predictors and outcomes like this:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1996</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">1000</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">10000</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, sep <span class="op">=</span> <span class="st">"_"</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span>, <span class="fl">0.5</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x_subset</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span> ,<span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p</span>, <span class="fl">100</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>1. Because <code>x</code> and <code>y</code> are completely independent, you should not be able to predict <code>y</code> using <code>x</code> with accuracy larger than 0.5. Confirm this by running cross validation using logistic regression to fit the model. Because we have so many predictors, we selected a random sample <code>x_subset</code>. Use the subset when training the model. Hint: use the caret <code>train</code> function. The <code>results</code> component of the output of <code>train</code> shows you the accuracy. Ignore the warnings.</p>
<p>2. Now instead of a random selection of predictors, we are going to search for those that are most predictive of the outcome. We can do this by comparing the values for the <span class="math inline">\(y = 1\)</span> group to those in the <span class="math inline">\(y = 0\)</span> group, for each predictor, using a t-test. You can perform this step as follows:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">devtools</span><span class="fu">::</span><span class="fu"><a href="https://remotes.r-lib.org/reference/install_bioc.html">install_bioc</a></span><span class="op">(</span><span class="st">"genefilter"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"genefilter"</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">genefilter</span><span class="op">)</span></span>
<span><span class="va">tt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/genefilter/man/rowFtests.html">colttests</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Create a vector of the p-values and call it <code>pvals</code>.</p>
<p>3. Create an index <code>ind</code> with the column numbers of the predictors that were “statistically significantly” associated with <code>y</code>. Use a p-value cutoff of 0.01 to define “statistically significant”. How many predictors survive this cutoff?</p>
<p>4. Re-run the cross validation but after redefining <code>x_subset</code> to be the subset of <code>x</code> defined by the columns showing “statistically significant” association with <code>y</code>. What is the accuracy now?</p>
<p>5. Re-run the cross validation again, but this time using kNN. Try out the following grid of tuning parameters: <code>k = seq(101, 301, 25)</code>. Make a plot of the resulting accuracy.</p>
<p>6. In exercises 3 and 4, we see that despite the fact that <code>x</code> and <code>y</code> are completely independent, we were able to predict <code>y</code> with accuracy higher than 70%. We must be doing something wrong then. What is it?</p>
<ol type="a">
<li>The function <code>train</code> estimates accuracy on the same data it uses to train the algorithm.</li>
<li>We are over-fitting the model by including 100 predictors.</li>
<li>We used the entire dataset to select the columns used in the model. This step needs to be included as part of the algorithm. The cross validation was done <strong>after</strong> this selection.</li>
<li>The high accuracy is just due to random variability.</li>
</ol>
<p>7. Advanced. Re-do the cross validation but this time include the selection step in the cross validation. The accuracy should now be close to 50%.</p>
<p>8. Load the <code>tissue_gene_expression</code> dataset. Use the <code>train</code> function to predict tissue from gene expression. Use kNN. What <code>k</code> works best?</p>
<p>9. The <code>createResample</code> function can be used to create bootstrap samples. For example, we can create 10 bootstrap samples for the <code>mnist_27</code> dataset like this:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1995</span><span class="op">)</span></span>
<span><span class="va">indexes</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/createDataPartition.html">createResample</a></span><span class="op">(</span><span class="va">mnist_27</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">y</span>, <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>How many times do <code>3</code>, <code>4</code>, and <code>7</code> appear in the first re-sampled index?</p>
<p>10. We see that some numbers appear more than once and others appear no times. This must be so for each dataset to be independent. Repeat the exercise for all the re-sampled indexes.</p>


</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("http:\/\/rafalab\.dfci\.harvard\.edu\/dsbook-part-2");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../ml/smoothing.html" class="pagination-link" aria-label="Smoothing">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Smoothing</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../ml/algorithms.html" class="pagination-link" aria-label="Examples of algorithms">
        <span class="nav-page-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Examples of algorithms</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>Introduction to Data Science was written by Rafael A. Irizarry</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/rafalab/dsbook-part-2/blob/main/ml/resampling-methods.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/rafalab/dsbook-part-2/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


</body></html>