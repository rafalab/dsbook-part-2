<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Rafael A. Irizarry">
<title>28&nbsp; Conditional Expectations and Smoothing – Introduction to Data Science</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../ml/resampling-methods.html" rel="next">
<link href="../ml/evaluation-metrics.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../ml/intro-ml.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="../ml/conditionals-and-smoothing.html"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Conditional Expectations and Smoothing</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Introduction to Data Science</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/rafalab/dsbook-part-2" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Front Matter</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../summaries/intro-summaries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Summary Statistics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../summaries/distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../summaries/numerical-summaries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Numerical Summaries</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../summaries/comparing-groups.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Comparing Groups</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../summaries/reading-summaries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recommended Reading</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../prob/intro-to-prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob/connecting-data-and-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Connecting Data and Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob/discrete-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Discrete Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob/continuous-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Continuous Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob/random-variables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Random Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob/sampling-models-and-clt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sampling Models and the Central Limit Theorem</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob/reading-prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recommended Reading</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../inference/intro-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistical Inference</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/estimates-confidence-intervals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Estimates and Confidence Intervals</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Data-Driven Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Bayesian Statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/hierarchical-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Hierarchical Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/hypothesis-testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/bootstrap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Bootstrap</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference/reading-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recommended Reading</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../linear-models/intro-to-linear-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear Models</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Introduction to Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/linear-model-framework.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">The Linear Model Framework</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/treatment-effect-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Treatment Effect Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Generalized Linear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/association-not-causation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Association Is Not Causation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/multivariable-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Multivariable Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-models/reading-lm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recommended Reading</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../highdim/intro-highdim.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">High Dimensional Data</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/matrices-in-R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Working with Matrices in R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/linear-algebra.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Applied Linear Algebra</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/dimension-reduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Dimension Reduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/regularization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Regularization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/latent-factor-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Latent Factor Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../highdim/reading-highdim.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recommended reading</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../ml/intro-ml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/notation-and-terminology.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Notation and Terminology</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/evaluation-metrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Performance Metrics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/conditionals-and-smoothing.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Conditional Expectations and Smoothing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/resampling-methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Resampling and Model Assessment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/algorithms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Supervised Learning Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/ml-in-practice.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Building Machine Learning Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Unsupervised Learning: Clustering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ml/reading-ml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recommended reading</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#conditional-probabilities-and-expectations" id="toc-conditional-probabilities-and-expectations" class="nav-link active" data-scroll-target="#conditional-probabilities-and-expectations"><span class="header-section-number">28.1</span> Conditional probabilities and expectations</a></li>
  <li><a href="#conditional-expectations-minimize-squared-loss-function" id="toc-conditional-expectations-minimize-squared-loss-function" class="nav-link" data-scroll-target="#conditional-expectations-minimize-squared-loss-function"><span class="header-section-number">28.2</span> Conditional expectations minimize squared loss function</a></li>
  <li>
<a href="#sec-smoothing" id="toc-sec-smoothing" class="nav-link" data-scroll-target="#sec-smoothing"><span class="header-section-number">28.3</span> Smoothing</a>
  <ul class="collapse">
<li><a href="#sec-two-or-seven" id="toc-sec-two-or-seven" class="nav-link" data-scroll-target="#sec-two-or-seven">Example: Is it a 2 or a 7?</a></li>
  </ul>
</li>
  <li>
<a href="#local-smoothing-methods" id="toc-local-smoothing-methods" class="nav-link" data-scroll-target="#local-smoothing-methods"><span class="header-section-number">28.4</span> Local Smoothing Methods</a>
  <ul class="collapse">
<li><a href="#bin-smoothing" id="toc-bin-smoothing" class="nav-link" data-scroll-target="#bin-smoothing">Bin smoothing</a></li>
  <li><a href="#kernel-smoothers" id="toc-kernel-smoothers" class="nav-link" data-scroll-target="#kernel-smoothers">Kernel smoothers</a></li>
  <li><a href="#local-weighted-regression-loess" id="toc-local-weighted-regression-loess" class="nav-link" data-scroll-target="#local-weighted-regression-loess">Local weighted regression (loess)</a></li>
  <li><a href="#beware-of-default-smoothing-parameters" id="toc-beware-of-default-smoothing-parameters" class="nav-link" data-scroll-target="#beware-of-default-smoothing-parameters">Beware of default smoothing parameters</a></li>
  </ul>
</li>
  <li><a href="#sec-smoothing-ml-connection" id="toc-sec-smoothing-ml-connection" class="nav-link" data-scroll-target="#sec-smoothing-ml-connection"><span class="header-section-number">28.5</span> Connecting smoothing to machine learning</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">28.6</span> Exercises</a></li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/rafalab/dsbook-part-2/blob/main/ml/conditionals-and-smoothing.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/rafalab/dsbook-part-2/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../ml/intro-ml.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="../ml/conditionals-and-smoothing.html"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Conditional Expectations and Smoothing</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title"><span id="sec-ml-conditionals" class="quarto-section-identifier"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Conditional Expectations and Smoothing</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><p>In machine learning applications, we rarely can predict outcomes perfectly. Spam filters miss obvious junk mail, Siri mishears words, and sometimes your bank incorrectly flags a legitimate purchase as fraud. The main reason these mistakes occur is that <em>perfect prediction is often impossible</em>. In most real datasets, we find groups of observations that share identical predictor values but have different outcomes. Because a prediction rule is a function, identical inputs must produce identical outputs. So whenever the same predictor values occur with different outcomes, as in the previous chapter, where both males and females can be exactly the same height, no algorithm can be correct for all such cases.</p>
<p>But this does not mean we can’t build useful algorithms, ones far better than guessing and often better than human experts. To do this optimally, we use the probabilistic framework introduced in <a href="../linear-models/regression.html#sec-conditional-expectation" class="quarto-xref"><span>Section 15.3</span></a>. Even if individual outcomes differ, we assume that observations with the same predictor values share the <em>same underlying probability</em> of belonging to each class. For categorical outcomes, this leads naturally to modeling quantities such as</p>
<p><span class="math display">\[
\Pr(Y=1 \mid X=x),
\]</span></p>
<p>which summarize the best possible predictions we can hope to make.</p>
<p>This brings us to the concept of <em>smoothing</em>. In practice, these conditional probabilities are unknown and must be estimated from noisy data. Smoothing, also known as <em>curve fitting</em> or <em>low-pass filtering</em>, is a general technique for uncovering underlying trends when the exact shape of the trend is not known. The idea is that while the true relationship between predictors and outcomes varies smoothly, the data themselves include random fluctuations. Smoothing methods exploit this smoothness to estimate the underlying pattern, providing stable and interpretable approximations to quantities like <span class="math inline">\(\Pr(Y=1 \mid X=x)\)</span> that we rely on for machine learning algorithms. In fact, many of the most widely used machine learning algorithms can be viewed, either directly or indirectly, as smoothing procedures, which is why smoothing is a foundational concept in this field.</p>
<section id="conditional-probabilities-and-expectations" class="level2" data-number="28.1"><h2 data-number="28.1" class="anchored" data-anchor-id="conditional-probabilities-and-expectations">
<span class="header-section-number">28.1</span> Conditional probabilities and expectations</h2>
<p>We use the notation <span class="math inline">\((X_1 = x_1,\dots,X_p=x_p)\)</span> to represent the fact that we have observed values <span class="math inline">\(x_1,\dots,x_p\)</span> for covariates <span class="math inline">\(X_1, \dots, X_p\)</span>. This does not imply that the outcome <span class="math inline">\(Y\)</span> will take a specific value. Instead, it implies a specific probability. In particular, we denote the <em>conditional probabilities</em> for each class <span class="math inline">\(k\)</span> with:</p>
<p><span class="math display">\[
\mathrm{Pr}(Y=k \mid X_1 = x_1,\dots,X_p=x_p), \, \mbox{for}\,k=1,\dots,K.
\]</span></p>
<p>To avoid writing out all the predictors, we will use bold letters like this: <span class="math inline">\(\mathbf{X} \equiv (X_1,\dots,X_p)^\top\)</span> and <span class="math inline">\(\mathbf{x} \equiv (x_1,\dots,x_p)^\top\)</span>. We will also use the following notation for the conditional probability of being class <span class="math inline">\(k\)</span>:</p>
<p><span class="math display">\[
p_k(\mathbf{x}) = \mathrm{Pr}(Y=k \mid \mathbf{X}=\mathbf{x}), \, \mbox{for}\, k=1,\dots,K.
\]</span> Notice that the <span class="math inline">\(p_k(\mathbf{x})\)</span> have to add up to 1 for each <span class="math inline">\(\mathbf{x}\)</span>, so once we know <span class="math inline">\(K-1\)</span>, we know all <span class="math inline">\(K\)</span>.</p>
<p>When the outcome is binary, we only need to know 1, so we drop the <span class="math inline">\(k\)</span> and use the notation <span class="math inline">\(p(\mathbf{x}) = \mathrm{Pr}(Y=1 \mid \mathbf{X}=\mathbf{x})\)</span>.</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Do not be confused by the fact that we use the letter <span class="math inline">\(p\)</span> for two different things: the conditional probability <span class="math inline">\(p(\mathbf{x})\)</span> and the number of predictors <span class="math inline">\(p\)</span>.</p>
</div>
</div>
</div>
<p>These probabilities guide the construction of an algorithm that makes the best prediction: for any given <span class="math inline">\(\mathbf{x}\)</span>, we will predict the class <span class="math inline">\(k\)</span> with the largest probability among <span class="math inline">\(p_1(\mathbf{x}), p_2(\mathbf{x}), \dots p_K(\mathbf{x})\)</span>. In mathematical notation, we write it like this:</p>
<p><span class="math display">\[\hat{y}(\mathbf{x}) = \max_k p_k(\mathbf{x})\]</span></p>
<p>In machine learning, we refer to this as <em>Bayes’ Rule</em>. But this is a theoretical rule since, in practice, we don’t know <span class="math inline">\(p_k(\mathbf{x}), k=1,\dots,K\)</span>. In fact, estimating these conditional probabilities can be thought of as the main challenge of machine learning. The better our probability estimates <span class="math inline">\(\hat{p}_k(\mathbf{x})\)</span>, the better our predictor.</p>
<p>So how well we predict depends on two things: 1) how close are the <span class="math inline">\(\max_k p_k(\mathbf{x})\)</span> to 1 or 0 (perfect certainty) and 2) how close our estimates <span class="math inline">\(\hat{p}_k(\mathbf{x})\)</span> are to <span class="math inline">\(p_k(\mathbf{x})\)</span>. We can’t do anything about the first restriction as it is determined by the nature of the problem, so our energy goes into finding ways to best estimate conditional probabilities.</p>
<p>The first restriction does imply that we have limits as to how well even the best possible algorithm can perform. You should get used to the idea that while in some challenges we will be able to achieve almost perfect accuracy, with digit readers for example, in others, our success is restricted by the randomness of the process, such as medical diagnosis from biometric data.</p>
<p>Keep in mind that defining our prediction by maximizing the probability is not always optimal in practice and depends on the context. As discussed in <a href="evaluation-metrics.html" class="quarto-xref"><span>Chapter 27</span></a>, sensitivity and specificity may differ in importance. But even in these cases, having a good estimate of the <span class="math inline">\(p_k(x), k=1,\dots,K\)</span> will suffice for us to build optimal prediction models, since we can control the balance between specificity and sensitivity however we wish. For instance, we can simply change the cutoffs used to predict one outcome or the other. In the plane example, we may ground the plane anytime the probability of malfunction is lower than 1 in a million as opposed to the default 1/2 used when error types are equally undesired.</p>
<p>For binary data, you can think of the probability <span class="math inline">\(\mathrm{Pr}(Y=1 \mid \mathbf{X}=\mathbf{x})\)</span> as the proportion of 1s in the stratum of the population for which <span class="math inline">\(\mathbf{X}=\mathbf{x}\)</span>. Many of the algorithms we will learn can be applied to both categorical and continuous data due to the connection between <em>conditional probabilities</em> and <em>conditional expectations</em>.</p>
<p>Because the expectation is the average of values <span class="math inline">\(y_1,\dots,y_n\)</span> in the population, in the case in which the <span class="math inline">\(y\)</span>s are 0 or 1, the expectation is equivalent to the probability of randomly picking a one since the average is simply the proportion of ones:</p>
<p><span class="math display">\[
\mathrm{E}[Y \mid \mathbf{X}=\mathbf{x}]=\mathrm{Pr}(Y=1 \mid \mathbf{X}=\mathbf{x}).
\]</span></p>
<p>This implies that the conditional probability is a conditional expectation. As a result, we often only use the expectation to denote both the conditional probability and conditional expectation.</p>
<p>Just like with categorical outcomes, in most applications the same observed predictors do not guarantee the same continuous outcomes. Instead, we assume that the outcome follows the same conditional distribution. We will now explain why we use the conditional expectation to define our predictors.</p>
</section><section id="conditional-expectations-minimize-squared-loss-function" class="level2" data-number="28.2"><h2 data-number="28.2" class="anchored" data-anchor-id="conditional-expectations-minimize-squared-loss-function">
<span class="header-section-number">28.2</span> Conditional expectations minimize squared loss function</h2>
<p>Why do we care about the conditional expectation in machine learning? This is because the expected value has an attractive mathematical property: it minimizes the MSE. Specifically, of all possible predictions <span class="math inline">\(\hat{Y}\)</span>,</p>
<p><span class="math display">\[
\hat{Y} = \mathrm{E}[Y \mid \mathbf{X}=\mathbf{x}] \, \mbox{ minimizes } \, \mathrm{E}[ (\hat{Y} - Y)^2  \mid  \mathbf{X}=\mathbf{x}]
\]</span></p>
<p>Due to this property, a succinct description of the main task of machine learning is that we use data to estimate:</p>
<p><span class="math display">\[
f(\mathbf{x}) \equiv \mathrm{E}[Y  \mid  \mathbf{X}=\mathbf{x} ]
\]</span></p>
<p>for any set of features <span class="math inline">\(\mathbf{x} = (x_1, \dots, x_p)^\top\)</span>.</p>
<p>This is easier said than done, since this function can take any shape and <span class="math inline">\(p\)</span> can be very large. Consider a case in which we only have one predictor <span class="math inline">\(x\)</span>. The expectation <span class="math inline">\(\mathrm{E}[Y  \mid  X=x]\)</span> can be any function of <span class="math inline">\(x\)</span>: a line, a parabola, a sine wave, a step function, anything. It gets even more complicated when we consider instances with large <span class="math inline">\(p\)</span>, in which case <span class="math inline">\(f(\mathbf{x})\)</span> is a function of a multidimensional vector <span class="math inline">\(\mathbf{x}\)</span>. For example, in our digit reader example <span class="math inline">\(p = 784\)</span>!</p>
<p>The main way in which competing machine learning algorithms differ is in their approach to estimating this conditional expectation. Because we must estimate such a flexible and potentially high-dimensional function from noisy, finite data, we need strategies that extract the underlying signal without being overwhelmed by randomness. A common and powerful idea is to assume that although the data themselves may look scattered, the <em>true</em> function <span class="math inline">\(f(\mathbf{x})\)</span> varies smoothly as <span class="math inline">\(\mathbf{x}\)</span> changes. This assumption allows us to borrow strength from nearby points and produce stable estimates even when exact predictor values are rarely repeated. This brings us to the concept of <em>smoothing</em>, one of the most fundamental tools in machine learning, underpinning many of the algorithms we will study next.</p>
</section><section id="sec-smoothing" class="level2" data-number="28.3"><h2 data-number="28.3" class="anchored" data-anchor-id="sec-smoothing">
<span class="header-section-number">28.3</span> Smoothing</h2>
<p>Smoothing is a core idea in machine learning and statistical modeling: when data are noisy, we often assume that the underlying trend changes gradually rather than jumping erratically from point to point. The goal of smoothing is to recover this hidden structure from the data.</p>
<p>To motivate the idea, consider the plot below: the noise obscures the trend, but it does not destroy it, our task is to uncover the trend from the noisy data.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/signal-plus-noise-example-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>In the next sections, we explore how smoothing techniques accomplish this, starting with a simple case study that illustrates the challenges and the intuition behind the methods.</p>
<section id="sec-two-or-seven" class="level3"><h3 class="anchored" data-anchor-id="sec-two-or-seven">Example: Is it a 2 or a 7?</h3>
<p>To motivate the need for smoothing and make the connection with machine learning, we will construct a simplified version of the MNIST dataset with just two classes for the outcome and two predictors. Specifically, we define the challenge as building an algorithm that can determine if a digit is a 2 or 7 from the proportion of dark pixels in the upper left quadrant (<span class="math inline">\(X_1\)</span>) and the lower right quadrant (<span class="math inline">\(X_2\)</span>). We also selected a random sample of 1,000 digits divided into training and test sets. Both sets are almost evenly distributed with 2s and 7s.</p>
<p>The <strong>dslabs</strong> package includes this example in the object <code>mnist_27</code>. In the training set, we have 800 observations and in the test set we have 200. Each observation has:</p>
<ul>
<li>an outcome <span class="math inline">\(y_i\)</span>, indicating whether the digit is a 2 or a 7, and</li>
<li>a feature vector <span class="math inline">\(\mathbf{x}_i = (x_{i,1}, x_{i,2})^\top\)</span>, a point in two-dimensional space extracted from the image.</li>
</ul>
<p>So the datasets consists of pairs <span class="math inline">\((\mathbf{x}_i, y_i)\)</span>, where each <span class="math inline">\(\mathbf{x}_i\)</span> is a 2D feature and each <span class="math inline">\(y_i\)</span> is the corresponding digit label.</p>
<p>To illustrate how to interpret <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, we include four example images. On the left are the original images of the two digits with the largest and smallest values for <span class="math inline">\(X_1\)</span> and on the right we have the images corresponding to the largest and smallest values of <span class="math inline">\(X_2\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/two-or-seven-images-large-x1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>Here is a plot of the observed <span class="math inline">\(X_2\)</span> versus observed <span class="math inline">\(X_1\)</span> with color determining if <span class="math inline">\(y\)</span> is 2 (red) or 7 (blue):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/topepo/caret/">caret</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">dslabs</span><span class="op">)</span></span>
<span><span class="va">mnist_27</span><span class="op">$</span><span class="va">train</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x_1</span>, <span class="va">x_2</span>, color <span class="op">=</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/two-or-seven-scatter-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>We can immediately see some patterns. For example, if <span class="math inline">\(x_1\)</span> is large (there was a lot of ink in the upper-left part of the image), then the digit is probably a 7. Also, for smaller values of <span class="math inline">\(x_1\)</span>, the 2s appear to be in the mid range values of <span class="math inline">\(x_2\)</span>.</p>
<p>We can start getting a sense for why these predictors are useful, but also why the problem will be somewhat challenging.</p>
<p>We haven’t really learned any algorithms yet, so let’s try building an algorithm using a GLM. The model is simply:</p>
<p><span class="math display">\[
\log\frac{p(\mathbf{x})}{1-p(\mathbf{x})} = \beta_0 + \beta_1 x_1 + \beta_2 x_2
\]</span></p>
<p>We fit can fit this model to obtain an estimate <span class="math inline">\(\hat{p}(\mathbf{x})\)</span> by using the <code>glm</code> function. We define a decision rule by predicting <span class="math inline">\(\hat{y}(\mathbf{x})=1\)</span> if <span class="math inline">\(\hat{p}(\mathbf{x})&gt;0.5\)</span> and 0 otherwise.</p>
<p>If we do this, we get an accuracy of 0.775, well above 50%. Not bad for our first try. But can we do better?</p>
<p>Because we constructed the <code>mnist_27</code> example and we had at our disposal 60,000 digits in just the MNIST dataset, we used this to build the <em>true</em> conditional distribution <span class="math inline">\(p(\mathbf{x})\)</span>. Keep in mind that in practice we don’t have access to the true conditional distribution. We include it in this educational example because it permits the comparison of <span class="math inline">\(\hat{p}(\mathbf{x})\)</span> to the true <span class="math inline">\(p(\mathbf{x})\)</span>. This comparison teaches us the limitations of different algorithms.</p>
<p>We have stored the true <span class="math inline">\(p(\mathbf{x})\)</span> in the <code>mnist_27</code> and can plot it as an image. We draw a curve that separates values of <span class="math inline">\(\mathbf{x}\)</span> for which <span class="math inline">\(p(\mathbf{x}) &gt; 0.5\)</span> and those for which <span class="math inline">\(p(\mathbf{x}) &lt; 0.5\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/true-p-better-colors-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%"></p>
</figure>
</div>
</div>
</div>
<p>To start understanding the limitations of regression, first note that, beacuse <span class="math inline">\(p(\mathbf{x}) = 0.5 \iff \log p(\mathbf{x})/(1-p(\mathbf{x})) = 0\)</span>, with GLM <span class="math inline">\(\hat{p}(\mathbf{x})\)</span>, the boundary defined by <span class="math inline">\(p(\mathbf{x}) = 0.5\)</span> must satisfiy:</p>
<p><span class="math display">\[
\hat{\beta}_0 + \hat{\beta}_1 x_1 + \hat{\beta}_2 x_2 = 0 \implies
x_2 = -\hat{\beta}_0/\hat{\beta}_2  -\hat{\beta}_1/\hat{\beta}_2 x_1
\]</span></p>
<p>which implies <span class="math inline">\(x_2\)</span> must be a linear function of <span class="math inline">\(x_1\)</span>.</p>
<p>This suggests that our GLM approach has no chance of capturing the non-linear nature of the true <span class="math inline">\(p(\mathbf{x})\)</span>. Below is a visual representation of <span class="math inline">\(\hat{p}(\mathbf{x})\)</span> which clearly shows how it fails to capture the shape of <span class="math inline">\(p(\mathbf{x})\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/regression-p-hat-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%"></p>
</figure>
</div>
</div>
</div>
<p>We need something more flexible: a method that permits estimates with shapes other than a plane. Smoothing techniques permit this flexibility. We will start by describing nearest neighbor and kernel approaches. To understand why we cover this topic, remember that the concepts behind smoothing techniques are extremely useful in machine learning because conditional expectations/probabilities can be thought of as <em>trends</em> of unknown shapes that we need to estimate in the presence of uncertainty.</p>
</section></section><section id="local-smoothing-methods" class="level2" data-number="28.4"><h2 data-number="28.4" class="anchored" data-anchor-id="local-smoothing-methods">
<span class="header-section-number">28.4</span> Local Smoothing Methods</h2>
<p>To explain the main ideas behind smoothing concepts, we will focus first on a problem with just one predictor. We pick an example with a clear trend that is not linear:the 2008 US popular vote poll margin between Barack Obama and John McCain.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">polls_2008</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">day</span>, <span class="va">margin</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/polls-2008-data-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>Later we will learn how to extend smoothing ideas to higher dimensions.</p>
<p>For the purposes of the popular vote example, do not think of it as a forecasting problem. Instead, we are simply interested in learning the shape of the trend once we have all the data.</p>
<p>We assume that for any given day <span class="math inline">\(x\)</span>, there is a true preference among the electorate <span class="math inline">\(f(x)\)</span>, but due to the uncertainty introduced by the polling, each data point comes with an error <span class="math inline">\(\varepsilon\)</span>. A mathematical model for the observed poll margin is:</p>
<p><span class="math display">\[
Y_i = f(x_i) + \varepsilon_i
\]</span></p>
<p>To think of this as a machine learning problem, consider that we want to predict <span class="math inline">\(Y\)</span> given a day <span class="math inline">\(x\)</span>. We are interested in finding the true trend <span class="math inline">\(f(x) = \mathrm{E}[Y \mid X=x]\)</span>, but since we don’t know this conditional expectation, we have to estimate it.</p>
<p>Let’s start by using regression, since it is the only method we have learned up to now for this type of data. Below is estimate we obtain:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/linear-regression-not-flexible-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>The fitted regression line does not appear to describe the trend very well. For example, on September 4 (day -62), the Republican Convention was held and the data suggest that it gave John McCain a boost in the polls. However, the regression line does not capture this potential trend. To see the <em>lack of fit</em> more clearly, we note that points above the fitted line (blue) and those below (red) are not evenly distributed across days. We therefore need an alternative, more flexible approach.</p>
<p>Next we describe smoothing techniques that can overcome this limitation.</p>
<section id="bin-smoothing" class="level3"><h3 class="anchored" data-anchor-id="bin-smoothing">Bin smoothing</h3>
<p>The general idea of bin smoothing is to group data points into strata in which the value of <span class="math inline">\(f(x)\)</span> can be assumed to be constant. We can make this assumption when we think <span class="math inline">\(f(x)\)</span> changes slowly and, as a result, <span class="math inline">\(f(x)\)</span> is almost constant in small windows of <span class="math inline">\(x\)</span>.</p>
<p>For the <code>poll_200</code>8 data, the smoothness assumption means believing that public opinion does not shift dramatically from one day to the next. For example, we might assume that support remains roughly constant over the span of a week. With this assumption in place, several consecutive days share approximately the same expected value, giving us multiple observations that help us estimate the underlying trend at that point.</p>
<p>If we fix a day to be in the center of our week, call it <span class="math inline">\(x_0\)</span>, then for any other day <span class="math inline">\(x\)</span> such that <span class="math inline">\(|x - x_0| \leq h\)</span>, with <span class="math inline">\(h = 3.5\)</span>, we assume <span class="math inline">\(f(x)\)</span> is a constant <span class="math inline">\(f(x) = \mu\)</span>. This assumption implies that:</p>
<p><span class="math display">\[
E[Y_i | X_i = x_i ] \approx \mu \mbox{   if   }  |x_i - x_0| \leq 3.5
\]</span></p>
<p>In smoothing, we refer to <span class="math inline">\(h\)</span> as the <em>bandwidth</em>. The interval of points satisfying <span class="math inline">\(|x_i - x_0| \le h\)</span> is called the <em>window size</em> or <em>span</em>.</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>The terms <em>bandwidth</em>, <em>kernel radius</em>, <em>window size</em>, and <em>span</em> are sometimes used interchangeably, but their precise meaning depends on the convention. With the definition above, the window size is <strong>twice the bandwidth</strong>.</p>
<p>Some R functions, such as <code><a href="https://rdrr.io/r/stats/ksmooth.html">ksmooth()</a></code>, use the <strong>full window size</strong> as the bandwidth. Under that convention, a bandwidth of 7 corresponds to <span class="math inline">\(h = 3.5\)</span> in our notation.</p>
</div>
</div>
</div>
<p>This assumption implies that a good estimate for <span class="math inline">\(f(x_0)\)</span> is the average of the <span class="math inline">\(y_i\)</span> values in the window. If we define <span class="math inline">\(A_0\)</span> as the set of indexes <span class="math inline">\(i\)</span> such that <span class="math inline">\(|x_i - x_0| \leq 3.5\)</span> and <span class="math inline">\(N_0\)</span> as the number of indexes in <span class="math inline">\(A_0\)</span>, then our estimate is:</p>
<p><span class="math display">\[
\hat{f}(x_0) = \frac{1}{N_0} \sum_{i \in A_0}  y_i
\]</span></p>
<p>We make this calculation with each value of <span class="math inline">\(x\)</span> as the center.</p>
<p>In the poll example, for each day, we would compute the average of the values within a week with that day in the center. Here are two examples: <span class="math inline">\(x_0 = -125\)</span> and <span class="math inline">\(x_0 = -55\)</span>. The blue segment represents the resulting average.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/binsmoother-expained-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>By computing this mean for every point, we form an estimate of the underlying curve <span class="math inline">\(f(x)\)</span>. Below we show the procedure happening as we move from the -155 up to 0. At each value of <span class="math inline">\(x_0\)</span>, we keep the estimate <span class="math inline">\(\hat{f}(x_0)\)</span> and move on to the next point:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/binsmoother-animation.gif" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>The final code and resulting estimate look like this:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">span</span> <span class="op">&lt;-</span> <span class="fl">7</span> </span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">polls_2008</span>, <span class="fu"><a href="https://rdrr.io/r/stats/ksmooth.html">ksmooth</a></span><span class="op">(</span><span class="va">day</span>, <span class="va">margin</span>, kernel <span class="op">=</span> <span class="st">"box"</span>, bandwidth <span class="op">=</span> <span class="va">span</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">polls_2008</span> <span class="op">|&gt;</span> <span class="fu">mutate</span><span class="op">(</span>fit <span class="op">=</span> <span class="va">fit</span><span class="op">$</span><span class="va">y</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">day</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">margin</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">3</span>, alpha <span class="op">=</span> <span class="fl">.5</span>, color <span class="op">=</span> <span class="st">"grey"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">fit</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/binsmoother-final-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
</section><section id="kernel-smoothers" class="level3"><h3 class="anchored" data-anchor-id="kernel-smoothers">Kernel smoothers</h3>
<p>The bin smother’s estimate can look quite wiggly. One reason is that as the window slides, points abruptly enter or leave the bin, causing jumps in the average. We can reduce these discontinuities with a <em>kernel smoother</em>. A kernel smoother assigns a <em>weight</em> to each data point according to its distance from the target location <span class="math inline">\(x_0\)</span>, then forms a weighted average.</p>
<p>Formally, let <span class="math inline">\(K\)</span> be a nonnegative kernel function and let <span class="math inline">\(h&gt;0\)</span> be a <em>bandwidth</em>. Define weights</p>
<p><span class="math display">\[
w_{x_0}(x_i) = K\!\left(\frac{x_i - x_0}{h}\right),
\]</span></p>
<p>and estimate the trend at <span class="math inline">\(x_0\)</span> with</p>
<p><span class="math display">\[
\hat{f}(x_0) \;=\; \frac{\sum_{i=1}^N w_{x_0}(x_i)\,y_i}{\sum_{i=1}^N w_{x_0}(x_i)}.
\]</span></p>
<p>The bin smoother is a special case with the <em>boxcar</em> (or <em>uniform</em>) kernel <span class="math inline">\(K(u) = 1\)</span> if <span class="math inline">\(|u| \leq 1\)</span> and 0 otherwise, which corresponds to assigning weight 1 inside the window and 0 outside. This is why, in the code above, we used <code>kernel = "box"</code> with <code>ksmooth</code>. To attenuate the wiggles caused by abrupt point entry and exit, we can use a smooth kernel that gives more weight to points near <span class="math inline">\(x_0\)</span> and rapidly decays for distant points. The option <code>kernel = "normal"</code> in <code>ksmooth</code> does exactly this by using the standard normal density for <span class="math inline">\(K\)</span>.</p>
<p>Below we visualize the box and normal kernels for <span class="math inline">\(x_0 = -125\)</span> and <span class="math inline">\(h = 3.5\)</span>, showing how the boxcar kernel weighs all in-bin points equally, while the normal kernel downweights points near the edges.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/gaussian-kernel-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>The final code and resulting plot for the normal kernel look like this:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">polls_2008</span>, <span class="fu"><a href="https://rdrr.io/r/stats/ksmooth.html">ksmooth</a></span><span class="op">(</span><span class="va">day</span>, <span class="va">margin</span>, kernel <span class="op">=</span> <span class="st">"normal"</span>, bandwidth <span class="op">=</span> <span class="fl">7</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">polls_2008</span> <span class="op">|&gt;</span> <span class="fu">mutate</span><span class="op">(</span>smooth <span class="op">=</span> <span class="va">fit</span><span class="op">$</span><span class="va">y</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">day</span>, <span class="va">margin</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">3</span>, alpha <span class="op">=</span> <span class="fl">.5</span>, color <span class="op">=</span> <span class="st">"grey"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">day</span>, <span class="va">smooth</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/final-ksmooth-normal-kernel-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>Notice that this version looks smoother.</p>
<p>There are several functions in R that implement bin smoothers. One example is <code>ksmooth</code>, shown above. In practice, however, we typically prefer methods that use slightly more complex models than fitting a constant. The final result above, for example, is still somewhat wiggly in parts we don’t expect it to be (between -125 and -75, for example). Methods such as <code>loess</code>, which we explain next, improve on this.</p>
</section><section id="local-weighted-regression-loess" class="level3"><h3 class="anchored" data-anchor-id="local-weighted-regression-loess">Local weighted regression (loess)</h3>
<p>A limitation of the bin smoother approach just described is that we need small windows for the approximately constant assumptions to hold. As a result, we end up with a small number of data points to average and obtain imprecise estimates <span class="math inline">\(\hat{f}(x)\)</span>. Here we describe how <em>local weighted regression</em> (loess) permits us to consider larger window sizes. To do this, we will use a mathematical result, referred to as Taylor’s theorem, which tells us that if you look closely enough at any smooth function <span class="math inline">\(f(x)\)</span>, it will look like a line. To see why this makes sense, consider the curved edges gardeners make using straight-edged spades:</p>
<p><img src="img/garden.png" class="img-fluid"></p>
<p>(“Downing Street garden path edge”<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> by Flickr user Number 10<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. CC-BY 2.0 license<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.)</p>
<p>Instead of assuming the function is approximately constant in a window, we assume the function is locally linear. We can consider larger window sizes with the linear assumption than with a constant. Instead of the one-week window, we consider a larger one in which the trend is approximately linear. We start with a three-week window and later consider and evaluate other options:</p>
<p><span class="math display">\[
E[Y_i | X_i = x_i ] = \beta_0 + \beta_1 (x_i-x_0) \mbox{   if   }  |x_i - x_0| \leq 10.5
\]</span></p>
<p>For every point <span class="math inline">\(x_0\)</span>, loess defines a window and fits a line within that window. Here is an example showing the fits for <span class="math inline">\(x_0=-125\)</span> and <span class="math inline">\(x_0 = -55\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/loess-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>The fitted value at <span class="math inline">\(x_0\)</span> becomes our estimate <span class="math inline">\(\hat{f}(x_0)\)</span>. Below we show the procedure happening as we move from the -155 up to 0:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/loess-animation.gif" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>The final result is a smoother fit than the bin smoother since we use larger sample sizes to estimate our local parameters:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">total_days</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/diff.html">diff</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">polls_2008</span><span class="op">$</span><span class="va">day</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">span</span> <span class="op">&lt;-</span> <span class="fl">21</span><span class="op">/</span><span class="va">total_days</span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/loess.html">loess</a></span><span class="op">(</span><span class="va">margin</span> <span class="op">~</span> <span class="va">day</span>, degree <span class="op">=</span> <span class="fl">1</span>, span <span class="op">=</span> <span class="va">span</span>, data <span class="op">=</span> <span class="va">polls_2008</span><span class="op">)</span></span>
<span><span class="va">polls_2008</span> <span class="op">|&gt;</span> <span class="fu">mutate</span><span class="op">(</span>smooth <span class="op">=</span> <span class="va">fit</span><span class="op">$</span><span class="va">fitted</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">day</span>, <span class="va">margin</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">3</span>, alpha <span class="op">=</span> <span class="fl">.5</span>, color <span class="op">=</span> <span class="st">"grey"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">day</span>, <span class="va">smooth</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/final-loess-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>Different spans give us different estimates. We can see how different window sizes lead to different estimates:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/loess-multi-span-animation.gif" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>Here are the final estimates:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/loess-final-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>There are three other differences between <code>loess</code> and the typical bin smoother.</p>
<p>1. Rather than keeping the bin size the same, <code>loess</code> keeps the number of points used in the local fit the same. This number is controlled via the <code>span</code> argument, which expects a proportion. For example, if <code>N</code> is the number of data points and <code>span=0.5</code>, then for a given <span class="math inline">\(x\)</span>, <code>loess</code> will use the <code>0.5*N</code> closest points to <span class="math inline">\(x\)</span> for the fit.</p>
<p>2. When fitting a line locally, <code>loess</code> uses a <em>weighted</em> approach. Basically, instead of minimizing the residual sun of squares, we minimize a weighted version:</p>
<p><span class="math display">\[
\sum_{i=1}^N w_0(x_i) \left[y_i - \left\{\beta_0 + \beta_1 (x_i-x_0)\right\}\right]^2
\]</span></p>
<p>3. Instead of the Gaussian kernel, loess uses a function called the Tukey tri-weight:</p>
<p><span class="math display">\[
K(u)= \left( 1  - |u|^3\right)^3 \mbox{ if } |u| \leq 1 \mbox{ and } K(u) = 0 \mbox{ if } |u| &gt; 1
\]</span></p>
<p>To define the weights, we denote <span class="math inline">\(2h\)</span> as the window size and define <span class="math inline">\(w_0(x_i)\)</span> as above: <span class="math inline">\(w_0(x_i) = K\left(\frac{x_i - x_0}{h}\right)\)</span>.</p>
<p>This kernel differs from the Gaussian kernel in that more points get values closer to the max:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/triweight-kernel-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>4. <code>loess</code> has the option of fitting the local model <em>robustly</em>. An iterative algorithm is implemented in which, after fitting a model in one iteration, outliers are detected and down-weighted for the next iteration. To use this option, we use the argument <code>family="symmetric"</code>.</p>
<p><code>loess</code> can also fit local parabolas instead of lines. Taylor’s theorem also tells us that if you look at any mathematical function closely enough, it looks like a parabola. The theorem also states that you don’t have to look as closely when approximating with parabolas as you do when approximating with lines. This means we can make our windows even larger and fit parabolas instead of lines.</p>
<p><span class="math display">\[
E[Y_i | X_i = x_i ] = \beta_0 + \beta_1 (x_i-x_0) + \beta_2 (x_i-x_0)^2 \mbox{   if   }  |x_i - x_0| \leq h
\]</span></p>
<p>You may have noticed that when we showed the code for using loess, we set <code>degree = 1</code>. This tells loess to fit polynomials of degree 1, a fancy name for lines. If you read the help page for loess, you will see that the argument <code>degree</code> defaults to 2. By default, loess fits parabolas not lines. Here is a comparison of the fitting lines (red dashed) and fitting parabolas (orange solid):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">total_days</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/diff.html">diff</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">polls_2008</span><span class="op">$</span><span class="va">day</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">span</span> <span class="op">&lt;-</span> <span class="fl">28</span><span class="op">/</span><span class="va">total_days</span></span>
<span><span class="va">fit_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/loess.html">loess</a></span><span class="op">(</span><span class="va">margin</span> <span class="op">~</span> <span class="va">day</span>, degree <span class="op">=</span> <span class="fl">1</span>, span <span class="op">=</span> <span class="va">span</span>, data <span class="op">=</span> <span class="va">polls_2008</span><span class="op">)</span></span>
<span><span class="va">fit_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/loess.html">loess</a></span><span class="op">(</span><span class="va">margin</span> <span class="op">~</span> <span class="va">day</span>, span <span class="op">=</span> <span class="va">span</span>, data <span class="op">=</span> <span class="va">polls_2008</span><span class="op">)</span></span>
<span></span>
<span><span class="va">polls_2008</span> <span class="op">|&gt;</span> <span class="fu">mutate</span><span class="op">(</span>smooth_1 <span class="op">=</span> <span class="va">fit_1</span><span class="op">$</span><span class="va">fitted</span>, smooth_2 <span class="op">=</span> <span class="va">fit_2</span><span class="op">$</span><span class="va">fitted</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">day</span>, <span class="va">margin</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">3</span>, alpha <span class="op">=</span> <span class="fl">.5</span>, color <span class="op">=</span> <span class="st">"grey"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">day</span>, <span class="va">smooth_1</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">day</span>, <span class="va">smooth_2</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"orange"</span>, lty <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/polls-2008-parabola-line-loess-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>The <code>degree = 2</code> gives us more wiggly results. In general, we actually prefer <code>degree = 1</code> as it is less prone to this kind of noise.</p>
</section><section id="beware-of-default-smoothing-parameters" class="level3"><h3 class="anchored" data-anchor-id="beware-of-default-smoothing-parameters">Beware of default smoothing parameters</h3>
<p>The <code>geom_smooth</code> function in the <strong>ggplot2</strong> package supports a variety of smoothing methods. By default, it uses loess or a related method called Generalized Additive Model, the latter if any window of data exceeds 1000 observations. We can request that loess is used using the <code>method</code> function:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">polls_2008</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">day</span>, <span class="va">margin</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="va">loess</span>, formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/ggplot-loess-default-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>But be careful with default parameters as they are rarely optimal. However, you can conveniently change. For example, with <code>loess</code> you can use the following code:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">polls_2008</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">day</span>, <span class="va">margin</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="va">loess</span>, formulat <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span>, method.args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>span <span class="op">=</span> <span class="fl">0.15</span>, degree <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="conditionals-and-smoothing_files/figure-html/ggplot-loess-degree-1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
</section></section><section id="sec-smoothing-ml-connection" class="level2" data-number="28.5"><h2 data-number="28.5" class="anchored" data-anchor-id="sec-smoothing-ml-connection">
<span class="header-section-number">28.5</span> Connecting smoothing to machine learning</h2>
<p>To see how smoothing relates to machine learning with a concrete example, consider again the example from <a href="#sec-two-or-seven" class="quarto-xref"><span>Section 28.3.1</span></a>. If we define the outcome <span class="math inline">\(Y = 1\)</span> for digits that are seven and <span class="math inline">\(Y=0\)</span> for digits that are 2, then we are interested in estimating the conditional probability:</p>
<p><span class="math display">\[
p(\mathbf{x}) = \mathrm{Pr}(Y=1 \mid X_1=x_1 , X_2 = x_2).
\]</span></p>
<p>with <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> the two predictors defined in <a href="#sec-two-or-seven" class="quarto-xref"><span>Section 28.3.1</span></a>. In this example, the 0s and 1s we observe are “noisy” because for some regions the probabilities <span class="math inline">\(p(\mathbf{x})\)</span> are not that close to 0 or 1. We therefore need to estimate <span class="math inline">\(p(\mathbf{x})\)</span>. Smoothing is an alternative to accomplishing this. In <a href="#sec-two-or-seven" class="quarto-xref"><span>Section 28.3.1</span></a>, we saw that linear regression was not flexible enough to capture the non-linear nature of <span class="math inline">\(p(\mathbf{x})\)</span>, thus smoothing approaches provide an improvement. In <a href="resampling-methods.html#sec-knn-cv-intro" class="quarto-xref"><span>Section 29.1</span></a>, we describe a popular machine learning algorithm, k-nearest neighbors, which is based on the concept of smoothing.</p>
</section><section id="exercises" class="level2" data-number="28.6"><h2 data-number="28.6" class="anchored" data-anchor-id="exercises">
<span class="header-section-number">28.6</span> Exercises</h2>
<p>1. Compute conditional probabilities for being Male for the <code>heights</code> dataset. Round the heights to the closest inch. Plot the estimated conditional probability <span class="math inline">\(P(x) = \mathrm{Pr}(\mbox{Male} | \mbox{height}=x)\)</span> for each <span class="math inline">\(x\)</span>.</p>
<p>2. In the plot we just made, we see high variability for low values of height. This is because we have few data points in these strata. This time use the <code>quantile</code> function for quantiles <span class="math inline">\(0.1,0.2,\dots,0.9\)</span> and the <code>cut</code> function to assure each group has the same number of points. Hint: For any numeric vector <code>x</code>, you can create groups based on quantiles as we demonstrate below.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cut.html">cut</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span>, include.lowest <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>3. Generate data from a bivariate normal distribution using the <strong>MASS</strong> package like this:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">Sigma</span> <span class="op">&lt;-</span> <span class="fl">9</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="fl">1</span><span class="op">)</span>, <span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu">MASS</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html">mvrnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10000</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">69</span>, <span class="fl">69</span><span class="op">)</span>, <span class="va">Sigma</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/stats/setNames.html">setNames</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="st">"y"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can make a quick plot of the data using <code>plot(dat)</code>. Use an approach similar to the previous exercise to estimate the conditional expectations and make a plot.</p>
<p>4. The <strong>dslabs</strong> package provides the following dataset with mortality counts for Puerto Rico for 2015-2018.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">dslabs</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">pr_death_counts</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Remove data from before May 2018, then use the <code>loess</code> function to obtain a smooth estimate of the expected number of deaths as a function of date. Plot this resulting smooth function. Make the span about two months long.</p>
<p>5. Plot the smooth estimates against day of the year, all on the same plot but with different colors.</p>
<p>6. Suppose we want to predict 2s and 7s in our <code>mnist_27</code> dataset with just the second covariate. Can we do this? On first inspection it appears the data does not have much predictive power. In fact, if we fit a regular logistic regression, the coefficient for <code>x_2</code> is not significant!</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">dslabs</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x_2</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, data <span class="op">=</span> <span class="va">mnist_27</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Plotting a scatterplot here is not useful since <code>y</code> is binary:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(mnist_27<span class="sc">$</span>train, <span class="fu">plot</span>(x_2, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Fit a loess line to the data above and plot the results. Notice that there is predictive power, except the conditional probability is not linear.</p>


</section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>https://www.flickr.com/photos/49707497@N06/7361631644<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>https://www.flickr.com/photos/number10gov/<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>https://creativecommons.org/licenses/by/2.0/<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("http:\/\/rafalab\.dfci\.harvard\.edu\/dsbook-part-2");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../ml/evaluation-metrics.html" class="pagination-link" aria-label="Performance Metrics">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Performance Metrics</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../ml/resampling-methods.html" class="pagination-link" aria-label="Resampling and Model Assessment">
        <span class="nav-page-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Resampling and Model Assessment</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>Introduction to Data Science was written by Rafael A. Irizarry</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/rafalab/dsbook-part-2/blob/main/ml/conditionals-and-smoothing.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/rafalab/dsbook-part-2/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


</body></html>