# Margin of Error {#sec-moe}

Pollsters summarize uncertainty using a single, easy-to-interpret number called the *margin of error*. The margin of error, together with the estimate of the parameter, allows them to report an interval that they are _very confident_ contains the true value. But what does "very confident" actually mean? 


Using the CLT, we can quantify this statement and connect it directly to probability.

Pollsters often report results such as "Candidate A leads by 3 points with a margin of error of $\pm 2$\%." The *margin of error* provides a simple way to summarize uncertainty. It reflects how confident pollsters are that their reported estimate is close to the true population value. But what exactly does "confident" mean, and how do we quantify it?

To discuss *confidence*, we turn to **probability**. In a poll, we can ask questions such as:

> How likely is it that our sample estimate $\bar{X}$ is within 2% of the true population proportion $p$?

To answer this, we need to know the **probability distribution** of our estimate. Each time we repeat the poll, we get a slightly different result, so $\bar{X}$ is a random variable with its own distribution, often called the *sampling distribution*. If we can describe this distribution mathematically, we can compute the probability that our estimate is close to $p$.

## The Central Limit Theorem {#sec-clt}

This is where the **Central Limit Theorem (CLT)** comes in. In the *Probability* part of the book @sec-clt-prob, we saw that when the sample size is large, the average of independent draws from a population is approximately normally distributed, regardless of the population's shape. Here, we apply the CLT to inference. 

Our poll estimate $\bar{X}$ is an average of independent draws, so it follows an approximately normal distribution centered at the true parameter $p$, with standard error $\sqrt{p(1-p)/N}$.
We can use this fact to answer the question. The probability that $\bar{X}$ is within 2% of the true population proportion $p$ is:


$$
\Pr(|\bar{X} - p| \leq 0.02)
= \Pr(\bar{X} \leq p + 0.02) - \Pr(\bar{X} \leq p - 0.02).
$$

We standardize $\bar{X}$ using the expected value and standard error to obtain a standard normal random variable $Z$:

$$
Z = \frac{\bar{X} - \mathrm{E}[\bar{X}]}{\mathrm{SE}[\bar{X}]}.
$$

Since $p$ is the expected value and $\mathrm{SE}(\bar{X}) = \sqrt{p(1-p)/N}$, we can rewrite the probability as

$$
\Pr\!\left(Z \leq \frac{0.02}{\mathrm{SE}(\bar{X})}\right)
- \Pr\!\left(Z \leq -\frac{0.02}{\mathrm{SE}(\bar{X})}\right).
$$

The challenge, of course, is that we don't know $p$, so we can't compute $\mathrm{SE}(\bar{X})$ exactly. Instead, we estimate it using the observed $\bar{X}$, a *plug-in estimate*:

$$
\hat{\mathrm{SE}}(\bar{X}) = \sqrt{\bar{X}(1 - \bar{X})/N}.
$$

In statistics, a hat indicates an estimate obtained from data.

Using our estimate $\bar{X} = 0.48$ from our earlier poll of $N = 25$ people we obtain:

```{r}
x_hat <- 0.48
se <- sqrt(x_hat*(1 - x_hat)/25)
se
```

Now we can compute the probability that our estimate is within 2% of the truth:

```{r}
pnorm(0.02/se) - pnorm(-0.02/se)
```

There's only a small chance of being this close when $N = 25$. Small polls lead to large uncertainty.

## Computing the 95% Margin of Error

Pollsters typically report an interval that they are *95% confident* contains the true parameter.
Under the CLT, 95% of a normal distribution lies within about **1.96 standard errors** of the mean.
Thus, the *margin of error* is

```{r}
1.96*se
```

Why 1.96? Because

```{r}
pnorm(1.96) - pnorm(-1.96)
```

equals roughly 95%. In other words, there is about a 95% probability that $\bar{X}$ falls within $1.96 \times \hat{\mathrm{SE}}(\bar{X})$ of $p$.
For our small poll, this corresponds to approximately `r round(1.96 * se, 2)`.
Larger polls reduce the standard error, and therefore the margin of error.

From the Real Clear Politics data in the previous chapter, we saw that typical polls sample between 700 and 3,500 respondents.
If $\bar{X} = 0.48$ were based on $N = 2,000$, then:

```{r}
n <- 2000
se <- sqrt(0.48*(1 - 0.48)/n)
round(1.96*se*100)
```

The margin of error would be about 2%, producing a much more informative result.


The CLT provides the mathematical foundation for understanding uncertainty in estimates and for computing the margin of error.
In the next section, we extend these ideas to construct **confidence intervals**, which formalize how we express uncertainty about unknown parameters.

## A Monte Carlo check

We can confirm this reasoning with a Monte Carlo simulation. Suppose the true proportion is $p = 0.45$ and we run $B = 10,000$ simulated polls, each with $N = 1000$ respondents:

```{r}
p <- 0.45
N <- 1000
B <- 10000
x_hat <- replicate(B, {
  x <- sample(c(0, 1), size = N, replace = TRUE, prob = c(1 - p, p))
  mean(x)
})
```

The CLT predicts that $\bar{X}$ has expected value $p = 0.45$ and standard error $\sqrt{p(1-p)/N}$.
The simulation confirms this:

```{r}
mean(x_hat)
sd(x_hat)
```

and the histogram and QQ plot verify the normal approximation.

```{r normal-approximation-for-polls, echo=FALSE, warning=FALSE, message=FALSE, out.width="100%", fig.height=3, cache=FALSE}
library(tidyverse)
library(gridExtra)
p1 <- data.frame(x_hat = x_hat) |> 
  ggplot(aes(x_hat)) + 
  geom_histogram(binwidth = 0.005, color = "black")
p2 <-  data.frame(x_hat = x_hat) |> 
  ggplot(aes(sample = x_hat)) + 
  stat_qq(dparams = list(mean = mean(x_hat), sd = sd(x_hat))) +
  geom_abline() + 
  ylab("x_hat") + 
  xlab("Theoretical normal")
grid.arrange(p1, p2, nrow = 1)
```

The results show that the theoretical margin of error accurately describes the variation we observe across many polls.

## Why not just run a huge poll?

If we polled 100,000 people, the margin of error would shrink below 0.3%:

```{r standard-error-versus-p, echo=FALSE}
N <- 100000
p <- seq(0.35, 0.65, length = 100)
se <- sapply(p, function(x) 1.96*sqrt(x*(1 - x)/N))
data.frame(p = p, SE = se) |> ggplot(aes(p, SE)) + geom_line()
```

So why don't pollsters do this?
Cost is one reason, but another is **bias**. Real polls are not simple random samples: people might decline to respond, lie, or be unreachable. Moreover, we can't perfectly define the population—only eligible voters, registered voters, or likely voters. These imperfections introduce systematic errors that the margin of error does not capture. Historically, U.S. popular-vote polls have shown biases of about 2–3%, which is why modeling bias is an important part of election forecasting (a topic we revisit later).


## Exercises

1\. Write an *urn model* function that takes the proportion of Democrats $p$ and the sample size $N$ as arguments, and returns the sample average if Democrats are 1s and Republicans are 0s. Call the function `take_sample`.

2\. Now assume `p <- 0.45` and that your sample size is $N=100$. Take a sample 10,000 times and save the vector of `mean(X) - p` into an object called `errors`. Hint: Use the function you wrote for exercise 1 to write this in one line of code.

3\. The vector `errors` contains, for each simulated sample, the difference between the actual $p$ and our estimate $\bar{X}$. We refer to this difference as the *error*. Compute the average and make a histogram of the errors generated in the Monte Carlo simulation, and select which of the following best describes their distributions:

```{r, eval=FALSE}
mean(errors)
hist(errors)
```

a.  The errors are all about 0.05.
b.  The errors are all about -0.05.
c.  The errors are symmetrically distributed around 0.
d.  The errors range from -1 to 1.

4\. The error $\bar{X}-p$ is a random variable. In practice, the error is not observed because we do not know $p$. Here, we observe it since we constructed the simulation. What is the average size of the error if we define the size by taking the absolute value $\mid \bar{X} - p \mid$?

5\. The standard error is related to the typical **size** of the error we make when predicting. For mathematical reasons related to the Central Limit Theorem, we actually use the standard deviation of `errors`, rather than the average of the absolute values, to quantify the typical size. What is this standard deviation of the errors?

6\. The theory we just learned tells us what this standard deviation is going to be because it is the standard error of $\bar{X}$. What does theory tell us is the standard error of $\bar{X}$ for a sample size of 100?

7\. In practice, we don't know $p$, so we construct an estimate of the theoretical prediction by plugging in $\bar{X}$ for $p$. Compute this estimate. Set the seed at 1 with `set.seed(1)`.

8\. Note how close the standard error estimates obtained from the Monte Carlo simulation (exercise 5), the theoretical prediction (exercise 6), and the estimate of the theoretical prediction (exercise 7) are. The theory is working and it gives us a practical approach to knowing the typical error we will make if we predict $p$ with $\bar{X}$. Another advantage that the theoretical result provides is that it gives an idea of how large a sample size is required to obtain the precision we need. Earlier, we learned that the largest standard errors occur for $p=0.5$. Create a plot of the largest standard error for $N$ ranging from 100 to 5,000. Based on this plot, how large does the sample size have to be to have a standard error of about 1%?

a.  100
b.  500
c.  2,500
d.  4,000

9\. For sample size $N=100$, the Central Limit Theorem tells us that the distribution of $\bar{X}$ is:

a.  practically equal to $p$.
b.  approximately normal with expected value $p$ and standard error $\sqrt{p(1-p)/N}$.
c.  approximately normal with expected value $\bar{X}$ and standard error $\sqrt{\bar{X}(1-\bar{X})/N}$.
d.  not a random variable.

10\. Based on the answer from exercise 8, the error $\bar{X} - p$ is:

a.  practically equal to 0.
b.  approximately normal with expected value $0$ and standard error $\sqrt{p(1-p)/N}$.
c.  approximately normal with expected value $p$ and standard error $\sqrt{p(1-p)/N}$.
d.  not a random variable.

11\. To corroborate your answer to exercise 9, make a qq-plot of the `errors` you generated in exercise 2 to see if they follow a normal distribution.

12\. If $p=0.45$ and $N=100$ as in exercise 2, use the CLT to estimate the probability that $\bar{X}>0.5$. Assume you know $p=0.45$ for this calculation.

13\. Assume you are in a practical situation and you don't know $p$. Take a sample of size $N=100$ and obtain a sample average of $\bar{X} = 0.51$. What is the CLT approximation for the probability that your error is equal to or larger than 0.01?
